{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 3 - Migration from Relational to NoSQL\n",
    "\n",
    "Student Name: Nirav Patel\n",
    "\n",
    "Student ID: 40248940\n",
    "\n",
    "Date: April 8, 2025\n",
    "\n",
    "> The Python scripts that you will see in this file, and that can be viewed in the `scripts` folder use environment variables.\n",
    "\n",
    "> You may set the required variables as explained in the `README.md` if you wish to run the scripts.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We begin by providing the DDL that is used to create the tables for the first data source, which is the Starwars API.\n",
    "\n",
    "This file is conatined in the `ddl` folder. Running this SQL code is NOT required as the following Python code handles it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "-- Drop tables if they exist\n",
    "DROP TABLE IF EXISTS people_films CASCADE;\n",
    "DROP TABLE IF EXISTS people_species CASCADE;\n",
    "DROP TABLE IF EXISTS people_starships CASCADE;\n",
    "DROP TABLE IF EXISTS people_vehicles CASCADE;\n",
    "DROP TABLE IF EXISTS films_species CASCADE;\n",
    "DROP TABLE IF EXISTS films_starships CASCADE;\n",
    "DROP TABLE IF EXISTS films_vehicles CASCADE;\n",
    "DROP TABLE IF EXISTS films_planets CASCADE;\n",
    "\n",
    "DROP TABLE IF EXISTS people CASCADE;\n",
    "DROP TABLE IF EXISTS films CASCADE;\n",
    "DROP TABLE IF EXISTS starships CASCADE;\n",
    "DROP TABLE IF EXISTS vehicles CASCADE;\n",
    "DROP TABLE IF EXISTS species CASCADE;\n",
    "DROP TABLE IF EXISTS planets CASCADE;\n",
    "\n",
    "-- Create tables\n",
    "CREATE TABLE people (\n",
    "    id SERIAL PRIMARY KEY,\n",
    "    name VARCHAR(255) NOT NULL,\n",
    "    birth_year VARCHAR(20),\n",
    "    eye_color VARCHAR(50),\n",
    "    gender VARCHAR(20),\n",
    "    hair_color VARCHAR(50),\n",
    "    height VARCHAR(20),\n",
    "    mass VARCHAR(20),\n",
    "    skin_color VARCHAR(50),\n",
    "    homeworld VARCHAR(255),\n",
    "    url VARCHAR(255) UNIQUE NOT NULL,\n",
    "    created TIMESTAMP,\n",
    "    edited TIMESTAMP\n",
    ");\n",
    "\n",
    "CREATE TABLE films (\n",
    "    id SERIAL PRIMARY KEY,\n",
    "    title VARCHAR(255) NOT NULL,\n",
    "    episode_id INTEGER NOT NULL,\n",
    "    opening_crawl TEXT,\n",
    "    director VARCHAR(255),\n",
    "    producer VARCHAR(255),\n",
    "    release_date DATE,\n",
    "    url VARCHAR(255) UNIQUE NOT NULL,\n",
    "    created TIMESTAMP,\n",
    "    edited TIMESTAMP\n",
    ");\n",
    "\n",
    "CREATE TABLE starships (\n",
    "    id SERIAL PRIMARY KEY,\n",
    "    name VARCHAR(255) NOT NULL,\n",
    "    model VARCHAR(255),\n",
    "    starship_class VARCHAR(255),\n",
    "    manufacturer VARCHAR(255),\n",
    "    cost_in_credits VARCHAR(50),\n",
    "    length VARCHAR(50),\n",
    "    crew VARCHAR(50),\n",
    "    passengers VARCHAR(50),\n",
    "    max_atmosphering_speed VARCHAR(50),\n",
    "    hyperdrive_rating VARCHAR(50),\n",
    "    MGLT VARCHAR(50),\n",
    "    cargo_capacity VARCHAR(50),\n",
    "    consumables VARCHAR(255),\n",
    "    url VARCHAR(255) UNIQUE NOT NULL,\n",
    "    created TIMESTAMP,\n",
    "    edited TIMESTAMP\n",
    ");\n",
    "\n",
    "CREATE TABLE vehicles (\n",
    "    id SERIAL PRIMARY KEY,\n",
    "    name VARCHAR(255) NOT NULL,\n",
    "    model VARCHAR(255),\n",
    "    vehicle_class VARCHAR(255),\n",
    "    manufacturer VARCHAR(255),\n",
    "    length VARCHAR(50),\n",
    "    cost_in_credits VARCHAR(50),\n",
    "    crew VARCHAR(50),\n",
    "    passengers VARCHAR(50),\n",
    "    max_atmosphering_speed VARCHAR(50),\n",
    "    cargo_capacity VARCHAR(50),\n",
    "    consumables VARCHAR(255),\n",
    "    url VARCHAR(255) UNIQUE NOT NULL,\n",
    "    created TIMESTAMP,\n",
    "    edited TIMESTAMP\n",
    ");\n",
    "\n",
    "CREATE TABLE species (\n",
    "    id SERIAL PRIMARY KEY,\n",
    "    name VARCHAR(255) NOT NULL,\n",
    "    classification VARCHAR(255),\n",
    "    designation VARCHAR(50),\n",
    "    average_height VARCHAR(50),\n",
    "    average_lifespan VARCHAR(50),\n",
    "    eye_colors VARCHAR(255),\n",
    "    hair_colors VARCHAR(255),\n",
    "    skin_colors VARCHAR(255),\n",
    "    language VARCHAR(255),\n",
    "    homeworld VARCHAR(255),\n",
    "    url VARCHAR(255) UNIQUE NOT NULL,\n",
    "    created TIMESTAMP,\n",
    "    edited TIMESTAMP\n",
    ");\n",
    "\n",
    "CREATE TABLE planets (\n",
    "    id SERIAL PRIMARY KEY,\n",
    "    name VARCHAR(255) NOT NULL,\n",
    "    diameter VARCHAR(50),\n",
    "    rotation_period VARCHAR(50),\n",
    "    orbital_period VARCHAR(50),\n",
    "    gravity VARCHAR(50),\n",
    "    population VARCHAR(50),\n",
    "    climate VARCHAR(255),\n",
    "    terrain VARCHAR(255),\n",
    "    surface_water VARCHAR(50),\n",
    "    url VARCHAR(255) UNIQUE NOT NULL,\n",
    "    created TIMESTAMP,\n",
    "    edited TIMESTAMP\n",
    ");\n",
    "\n",
    "-- Relationship Tables for Many-to-Many Relationships\n",
    "CREATE TABLE people_films (\n",
    "    person_url VARCHAR(255) REFERENCES people(url) ON DELETE CASCADE,\n",
    "    film_url VARCHAR(255) REFERENCES films(url) ON DELETE CASCADE,\n",
    "    PRIMARY KEY (person_url, film_url)\n",
    ");\n",
    "\n",
    "CREATE TABLE people_species (\n",
    "    person_url VARCHAR(255) REFERENCES people(url) ON DELETE CASCADE,\n",
    "    species_url VARCHAR(255) REFERENCES species(url) ON DELETE CASCADE,\n",
    "    PRIMARY KEY (person_url, species_url)\n",
    ");\n",
    "\n",
    "CREATE TABLE people_starships (\n",
    "    person_url VARCHAR(255) REFERENCES people(url) ON DELETE CASCADE,\n",
    "    starship_url VARCHAR(255) REFERENCES starships(url) ON DELETE CASCADE,\n",
    "    PRIMARY KEY (person_url, starship_url)\n",
    ");\n",
    "\n",
    "CREATE TABLE people_vehicles (\n",
    "    person_url VARCHAR(255) REFERENCES people(url) ON DELETE CASCADE,\n",
    "    vehicle_url VARCHAR(255) REFERENCES vehicles(url) ON DELETE CASCADE,\n",
    "    PRIMARY KEY (person_url, vehicle_url)\n",
    ");\n",
    "\n",
    "CREATE TABLE films_species (\n",
    "    film_url VARCHAR(255) REFERENCES films(url) ON DELETE CASCADE,\n",
    "    species_url VARCHAR(255) REFERENCES species(url) ON DELETE CASCADE,\n",
    "    PRIMARY KEY (film_url, species_url)\n",
    ");\n",
    "\n",
    "CREATE TABLE films_starships (\n",
    "    film_url VARCHAR(255) REFERENCES films(url) ON DELETE CASCADE,\n",
    "    starship_url VARCHAR(255) REFERENCES starships(url) ON DELETE CASCADE,\n",
    "    PRIMARY KEY (film_url, starship_url)\n",
    ");\n",
    "\n",
    "CREATE TABLE films_vehicles (\n",
    "    film_url VARCHAR(255) REFERENCES films(url) ON DELETE CASCADE,\n",
    "    vehicle_url VARCHAR(255) REFERENCES vehicles(url) ON DELETE CASCADE,\n",
    "    PRIMARY KEY (film_url, vehicle_url)\n",
    ");\n",
    "\n",
    "CREATE TABLE films_planets (\n",
    "    film_url VARCHAR(255) REFERENCES films(url) ON DELETE CASCADE,\n",
    "    planet_url VARCHAR(255) REFERENCES planets(url) ON DELETE CASCADE,\n",
    "    PRIMARY KEY (film_url, planet_url)\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now provide the code used to fetch data for the desired entities from the API using Python.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Star Wars Schema executed successfully.\n",
      "\n",
      "Fetching people...\n",
      "Inserting 82 records into people...\n",
      "Inserting non-relationship data into table: people\n",
      "\n",
      "Fetching films...\n",
      "Inserting 6 records into films...\n",
      "Inserting non-relationship data into table: films\n",
      "\n",
      "Fetching planets...\n",
      "Inserting 60 records into planets...\n",
      "Inserting non-relationship data into table: planets\n",
      "\n",
      "Fetching species...\n",
      "Inserting 37 records into species...\n",
      "Inserting non-relationship data into table: species\n",
      "\n",
      "Fetching vehicles...\n",
      "Inserting 39 records into vehicles...\n",
      "Inserting non-relationship data into table: vehicles\n",
      "\n",
      "Fetching starships...\n",
      "Inserting 36 records into starships...\n",
      "Inserting non-relationship data into table: starships\n",
      "Inserting relationship data for people...\n",
      "Inserting into people_films: person_url=https://swapi.dev/api/people/1/ film_url=https://swapi.dev/api/films/1/\n",
      "Inserting into people_films: person_url=https://swapi.dev/api/people/1/ film_url=https://swapi.dev/api/films/2/\n",
      "Inserting into people_films: person_url=https://swapi.dev/api/people/1/ film_url=https://swapi.dev/api/films/3/\n",
      "Inserting into people_films: person_url=https://swapi.dev/api/people/1/ film_url=https://swapi.dev/api/films/6/\n",
      "Inserting into people_films: person_url=https://swapi.dev/api/people/2/ film_url=https://swapi.dev/api/films/1/\n",
      "Inserting into people_films: person_url=https://swapi.dev/api/people/2/ film_url=https://swapi.dev/api/films/2/\n",
      "Inserting into people_films: person_url=https://swapi.dev/api/people/2/ film_url=https://swapi.dev/api/films/3/\n",
      "Inserting into people_films: person_url=https://swapi.dev/api/people/2/ film_url=https://swapi.dev/api/films/4/\n",
      "Inserting into people_films: person_url=https://swapi.dev/api/people/2/ film_url=https://swapi.dev/api/films/5/\n",
      "Inserting into people_films: person_url=https://swapi.dev/api/people/2/ film_url=https://swapi.dev/api/films/6/\n",
      "Inserting into people_films: person_url=https://swapi.dev/api/people/3/ film_url=https://swapi.dev/api/films/1/\n",
      "Inserting into people_films: person_url=https://swapi.dev/api/people/3/ film_url=https://swapi.dev/api/films/2/\n",
      "Inserting into people_films: person_url=https://swapi.dev/api/people/3/ film_url=https://swapi.dev/api/films/3/\n",
      "Inserting into people_films: person_url=https://swapi.dev/api/people/3/ film_url=https://swapi.dev/api/films/4/\n",
      "Inserting into people_films: person_url=https://swapi.dev/api/people/3/ film_url=https://swapi.dev/api/films/5/\n",
      "Inserting into people_films: person_url=https://swapi.dev/api/people/3/ film_url=https://swapi.dev/api/films/6/\n",
      "Inserting into people_films: person_url=https://swapi.dev/api/people/4/ film_url=https://swapi.dev/api/films/1/\n",
      "Inserting into people_films: person_url=https://swapi.dev/api/people/4/ film_url=https://swapi.dev/api/films/2/\n",
      "Inserting into people_films: person_url=https://swapi.dev/api/people/4/ film_url=https://swapi.dev/api/films/3/\n",
      "Inserting into people_films: person_url=https://swapi.dev/api/people/4/ film_url=https://swapi.dev/api/films/6/\n",
      "Inserting into people_films: person_url=https://swapi.dev/api/people/5/ film_url=https://swapi.dev/api/films/1/\n",
      "Inserting into people_films: person_url=https://swapi.dev/api/people/5/ film_url=https://swapi.dev/api/films/2/\n",
      "Inserting into people_films: person_url=https://swapi.dev/api/people/5/ film_url=https://swapi.dev/api/films/3/\n",
      "Inserting into people_films: person_url=https://swapi.dev/api/people/5/ film_url=https://swapi.dev/api/films/6/\n",
      "Inserting into people_films: person_url=https://swapi.dev/api/people/6/ film_url=https://swapi.dev/api/films/1/\n",
      "Inserting into people_films: person_url=https://swapi.dev/api/people/6/ film_url=https://swapi.dev/api/films/5/\n",
      "Inserting into people_films: person_url=https://swapi.dev/api/people/6/ film_url=https://swapi.dev/api/films/6/\n",
      "Inserting into people_films: person_url=https://swapi.dev/api/people/7/ film_url=https://swapi.dev/api/films/1/\n",
      "Inserting into people_films: person_url=https://swapi.dev/api/people/7/ film_url=https://swapi.dev/api/films/5/\n",
      "Inserting into people_films: person_url=https://swapi.dev/api/people/7/ film_url=https://swapi.dev/api/films/6/\n",
      "Inserting into people_films: person_url=https://swapi.dev/api/people/8/ film_url=https://swapi.dev/api/films/1/\n",
      "Inserting into people_films: person_url=https://swapi.dev/api/people/9/ film_url=https://swapi.dev/api/films/1/\n",
      "Inserting into people_films: person_url=https://swapi.dev/api/people/10/ film_url=https://swapi.dev/api/films/1/\n",
      "Inserting into people_films: person_url=https://swapi.dev/api/people/10/ film_url=https://swapi.dev/api/films/2/\n",
      "Inserting into people_films: person_url=https://swapi.dev/api/people/10/ film_url=https://swapi.dev/api/films/3/\n",
      "Inserting into people_films: person_url=https://swapi.dev/api/people/10/ film_url=https://swapi.dev/api/films/4/\n",
      "Inserting into people_films: person_url=https://swapi.dev/api/people/10/ film_url=https://swapi.dev/api/films/5/\n",
      "Inserting into people_films: person_url=https://swapi.dev/api/people/10/ film_url=https://swapi.dev/api/films/6/\n",
      "Inserting into people_films: person_url=https://swapi.dev/api/people/11/ film_url=https://swapi.dev/api/films/4/\n",
      "Inserting into people_films: person_url=https://swapi.dev/api/people/11/ film_url=https://swapi.dev/api/films/5/\n",
      "Inserting into people_films: person_url=https://swapi.dev/api/people/11/ film_url=https://swapi.dev/api/films/6/\n",
      "Inserting into people_films: person_url=https://swapi.dev/api/people/12/ film_url=https://swapi.dev/api/films/1/\n",
      "Inserting into people_films: person_url=https://swapi.dev/api/people/12/ film_url=https://swapi.dev/api/films/6/\n",
      "Inserting into people_films: person_url=https://swapi.dev/api/people/13/ film_url=https://swapi.dev/api/films/1/\n",
      "Inserting into people_films: person_url=https://swapi.dev/api/people/13/ film_url=https://swapi.dev/api/films/2/\n",
      "Inserting into people_films: person_url=https://swapi.dev/api/people/13/ film_url=https://swapi.dev/api/films/3/\n",
      "Inserting into people_films: person_url=https://swapi.dev/api/people/13/ film_url=https://swapi.dev/api/films/6/\n",
      "Inserting into people_films: person_url=https://swapi.dev/api/people/14/ film_url=https://swapi.dev/api/films/1/\n",
      "Inserting into people_films: person_url=https://swapi.dev/api/people/14/ film_url=https://swapi.dev/api/films/2/\n",
      "Inserting into people_films: person_url=https://swapi.dev/api/people/14/ film_url=https://swapi.dev/api/films/3/\n",
      "Inserting into people_films: person_url=https://swapi.dev/api/people/15/ film_url=https://swapi.dev/api/films/1/\n",
      "Inserting into people_films: person_url=https://swapi.dev/api/people/16/ film_url=https://swapi.dev/api/films/1/\n",
      "Inserting into people_films: person_url=https://swapi.dev/api/people/16/ film_url=https://swapi.dev/api/films/3/\n",
      "Inserting into people_films: person_url=https://swapi.dev/api/people/16/ film_url=https://swapi.dev/api/films/4/\n",
      "Inserting into people_films: person_url=https://swapi.dev/api/people/18/ film_url=https://swapi.dev/api/films/1/\n",
      "Inserting into people_films: person_url=https://swapi.dev/api/people/18/ film_url=https://swapi.dev/api/films/2/\n",
      "Inserting into people_films: person_url=https://swapi.dev/api/people/18/ film_url=https://swapi.dev/api/films/3/\n",
      "Inserting into people_films: person_url=https://swapi.dev/api/people/19/ film_url=https://swapi.dev/api/films/1/\n",
      "Inserting into people_films: person_url=https://swapi.dev/api/people/20/ film_url=https://swapi.dev/api/films/2/\n",
      "Inserting into people_films: person_url=https://swapi.dev/api/people/20/ film_url=https://swapi.dev/api/films/3/\n",
      "Inserting into people_films: person_url=https://swapi.dev/api/people/20/ film_url=https://swapi.dev/api/films/4/\n",
      "Inserting into people_films: person_url=https://swapi.dev/api/people/20/ film_url=https://swapi.dev/api/films/5/\n",
      "Inserting into people_films: person_url=https://swapi.dev/api/people/20/ film_url=https://swapi.dev/api/films/6/\n",
      "Inserting into people_films: person_url=https://swapi.dev/api/people/21/ film_url=https://swapi.dev/api/films/2/\n",
      "Inserting into people_films: person_url=https://swapi.dev/api/people/21/ film_url=https://swapi.dev/api/films/3/\n",
      "Inserting into people_films: person_url=https://swapi.dev/api/people/21/ film_url=https://swapi.dev/api/films/4/\n",
      "Inserting into people_films: person_url=https://swapi.dev/api/people/21/ film_url=https://swapi.dev/api/films/5/\n",
      "Inserting into people_films: person_url=https://swapi.dev/api/people/21/ film_url=https://swapi.dev/api/films/6/\n",
      "Inserting into people_films: person_url=https://swapi.dev/api/people/22/ film_url=https://swapi.dev/api/films/2/\n",
      "Inserting into people_films: person_url=https://swapi.dev/api/people/22/ film_url=https://swapi.dev/api/films/3/\n",
      "Inserting into people_films: person_url=https://swapi.dev/api/people/22/ film_url=https://swapi.dev/api/films/5/\n",
      "Inserting into people_films: person_url=https://swapi.dev/api/people/23/ film_url=https://swapi.dev/api/films/2/\n",
      "Inserting into people_films: person_url=https://swapi.dev/api/people/24/ film_url=https://swapi.dev/api/films/2/\n",
      "Inserting into people_films: person_url=https://swapi.dev/api/people/25/ film_url=https://swapi.dev/api/films/2/\n",
      "Inserting into people_films: person_url=https://swapi.dev/api/people/25/ film_url=https://swapi.dev/api/films/3/\n",
      "Inserting into people_films: person_url=https://swapi.dev/api/people/26/ film_url=https://swapi.dev/api/films/2/\n",
      "Inserting into people_films: person_url=https://swapi.dev/api/people/27/ film_url=https://swapi.dev/api/films/3/\n",
      "Inserting into people_films: person_url=https://swapi.dev/api/people/28/ film_url=https://swapi.dev/api/films/3/\n",
      "Inserting into people_films: person_url=https://swapi.dev/api/people/29/ film_url=https://swapi.dev/api/films/3/\n",
      "Inserting into people_films: person_url=https://swapi.dev/api/people/30/ film_url=https://swapi.dev/api/films/3/\n",
      "Inserting into people_films: person_url=https://swapi.dev/api/people/31/ film_url=https://swapi.dev/api/films/3/\n",
      "Inserting into people_films: person_url=https://swapi.dev/api/people/32/ film_url=https://swapi.dev/api/films/4/\n",
      "Inserting into people_films: person_url=https://swapi.dev/api/people/33/ film_url=https://swapi.dev/api/films/4/\n",
      "Inserting into people_films: person_url=https://swapi.dev/api/people/33/ film_url=https://swapi.dev/api/films/5/\n",
      "Inserting into people_films: person_url=https://swapi.dev/api/people/33/ film_url=https://swapi.dev/api/films/6/\n",
      "Inserting into people_films: person_url=https://swapi.dev/api/people/34/ film_url=https://swapi.dev/api/films/4/\n",
      "Inserting into people_films: person_url=https://swapi.dev/api/people/35/ film_url=https://swapi.dev/api/films/4/\n",
      "Inserting into people_films: person_url=https://swapi.dev/api/people/35/ film_url=https://swapi.dev/api/films/5/\n",
      "Inserting into people_films: person_url=https://swapi.dev/api/people/35/ film_url=https://swapi.dev/api/films/6/\n",
      "Inserting into people_films: person_url=https://swapi.dev/api/people/36/ film_url=https://swapi.dev/api/films/4/\n",
      "Inserting into people_films: person_url=https://swapi.dev/api/people/36/ film_url=https://swapi.dev/api/films/5/\n",
      "Inserting into people_films: person_url=https://swapi.dev/api/people/37/ film_url=https://swapi.dev/api/films/4/\n",
      "Inserting into people_films: person_url=https://swapi.dev/api/people/38/ film_url=https://swapi.dev/api/films/4/\n",
      "Inserting into people_films: person_url=https://swapi.dev/api/people/39/ film_url=https://swapi.dev/api/films/4/\n",
      "Inserting into people_films: person_url=https://swapi.dev/api/people/40/ film_url=https://swapi.dev/api/films/4/\n",
      "Inserting into people_films: person_url=https://swapi.dev/api/people/40/ film_url=https://swapi.dev/api/films/5/\n",
      "Inserting into people_films: person_url=https://swapi.dev/api/people/41/ film_url=https://swapi.dev/api/films/4/\n",
      "Inserting into people_films: person_url=https://swapi.dev/api/people/42/ film_url=https://swapi.dev/api/films/4/\n",
      "Inserting into people_films: person_url=https://swapi.dev/api/people/43/ film_url=https://swapi.dev/api/films/4/\n",
      "Inserting into people_films: person_url=https://swapi.dev/api/people/43/ film_url=https://swapi.dev/api/films/5/\n",
      "Inserting into people_films: person_url=https://swapi.dev/api/people/44/ film_url=https://swapi.dev/api/films/4/\n",
      "Inserting into people_films: person_url=https://swapi.dev/api/people/45/ film_url=https://swapi.dev/api/films/3/\n",
      "Inserting into people_films: person_url=https://swapi.dev/api/people/46/ film_url=https://swapi.dev/api/films/4/\n",
      "Inserting into people_films: person_url=https://swapi.dev/api/people/46/ film_url=https://swapi.dev/api/films/5/\n",
      "Inserting into people_films: person_url=https://swapi.dev/api/people/46/ film_url=https://swapi.dev/api/films/6/\n",
      "Inserting into people_films: person_url=https://swapi.dev/api/people/47/ film_url=https://swapi.dev/api/films/4/\n",
      "Inserting into people_films: person_url=https://swapi.dev/api/people/48/ film_url=https://swapi.dev/api/films/4/\n",
      "Inserting into people_films: person_url=https://swapi.dev/api/people/49/ film_url=https://swapi.dev/api/films/4/\n",
      "Inserting into people_films: person_url=https://swapi.dev/api/people/50/ film_url=https://swapi.dev/api/films/4/\n",
      "Inserting into people_films: person_url=https://swapi.dev/api/people/51/ film_url=https://swapi.dev/api/films/4/\n",
      "Inserting into people_films: person_url=https://swapi.dev/api/people/51/ film_url=https://swapi.dev/api/films/5/\n",
      "Inserting into people_films: person_url=https://swapi.dev/api/people/51/ film_url=https://swapi.dev/api/films/6/\n",
      "Inserting into people_films: person_url=https://swapi.dev/api/people/52/ film_url=https://swapi.dev/api/films/4/\n",
      "Inserting into people_films: person_url=https://swapi.dev/api/people/52/ film_url=https://swapi.dev/api/films/5/\n",
      "Inserting into people_films: person_url=https://swapi.dev/api/people/52/ film_url=https://swapi.dev/api/films/6/\n",
      "Inserting into people_films: person_url=https://swapi.dev/api/people/53/ film_url=https://swapi.dev/api/films/4/\n",
      "Inserting into people_films: person_url=https://swapi.dev/api/people/53/ film_url=https://swapi.dev/api/films/5/\n",
      "Inserting into people_films: person_url=https://swapi.dev/api/people/53/ film_url=https://swapi.dev/api/films/6/\n",
      "Inserting into people_films: person_url=https://swapi.dev/api/people/54/ film_url=https://swapi.dev/api/films/4/\n",
      "Inserting into people_films: person_url=https://swapi.dev/api/people/54/ film_url=https://swapi.dev/api/films/6/\n",
      "Inserting into people_films: person_url=https://swapi.dev/api/people/55/ film_url=https://swapi.dev/api/films/4/\n",
      "Inserting into people_films: person_url=https://swapi.dev/api/people/55/ film_url=https://swapi.dev/api/films/6/\n",
      "Inserting into people_films: person_url=https://swapi.dev/api/people/56/ film_url=https://swapi.dev/api/films/4/\n",
      "Inserting into people_films: person_url=https://swapi.dev/api/people/56/ film_url=https://swapi.dev/api/films/6/\n",
      "Inserting into people_films: person_url=https://swapi.dev/api/people/57/ film_url=https://swapi.dev/api/films/4/\n",
      "Inserting into people_films: person_url=https://swapi.dev/api/people/58/ film_url=https://swapi.dev/api/films/4/\n",
      "Inserting into people_films: person_url=https://swapi.dev/api/people/58/ film_url=https://swapi.dev/api/films/5/\n",
      "Inserting into people_films: person_url=https://swapi.dev/api/people/58/ film_url=https://swapi.dev/api/films/6/\n",
      "Inserting into people_films: person_url=https://swapi.dev/api/people/59/ film_url=https://swapi.dev/api/films/4/\n",
      "Inserting into people_films: person_url=https://swapi.dev/api/people/59/ film_url=https://swapi.dev/api/films/5/\n",
      "Inserting into people_films: person_url=https://swapi.dev/api/people/60/ film_url=https://swapi.dev/api/films/5/\n",
      "Inserting into people_films: person_url=https://swapi.dev/api/people/61/ film_url=https://swapi.dev/api/films/5/\n",
      "Inserting into people_films: person_url=https://swapi.dev/api/people/62/ film_url=https://swapi.dev/api/films/5/\n",
      "Inserting into people_films: person_url=https://swapi.dev/api/people/63/ film_url=https://swapi.dev/api/films/5/\n",
      "Inserting into people_films: person_url=https://swapi.dev/api/people/63/ film_url=https://swapi.dev/api/films/6/\n",
      "Inserting into people_films: person_url=https://swapi.dev/api/people/64/ film_url=https://swapi.dev/api/films/5/\n",
      "Inserting into people_films: person_url=https://swapi.dev/api/people/64/ film_url=https://swapi.dev/api/films/6/\n",
      "Inserting into people_films: person_url=https://swapi.dev/api/people/65/ film_url=https://swapi.dev/api/films/5/\n",
      "Inserting into people_films: person_url=https://swapi.dev/api/people/66/ film_url=https://swapi.dev/api/films/5/\n",
      "Inserting into people_films: person_url=https://swapi.dev/api/people/67/ film_url=https://swapi.dev/api/films/5/\n",
      "Inserting into people_films: person_url=https://swapi.dev/api/people/67/ film_url=https://swapi.dev/api/films/6/\n",
      "Inserting into people_films: person_url=https://swapi.dev/api/people/68/ film_url=https://swapi.dev/api/films/5/\n",
      "Inserting into people_films: person_url=https://swapi.dev/api/people/68/ film_url=https://swapi.dev/api/films/6/\n",
      "Inserting into people_films: person_url=https://swapi.dev/api/people/69/ film_url=https://swapi.dev/api/films/5/\n",
      "Inserting into people_films: person_url=https://swapi.dev/api/people/70/ film_url=https://swapi.dev/api/films/5/\n",
      "Inserting into people_films: person_url=https://swapi.dev/api/people/71/ film_url=https://swapi.dev/api/films/5/\n",
      "Inserting into people_films: person_url=https://swapi.dev/api/people/72/ film_url=https://swapi.dev/api/films/5/\n",
      "Inserting into people_films: person_url=https://swapi.dev/api/people/73/ film_url=https://swapi.dev/api/films/5/\n",
      "Inserting into people_films: person_url=https://swapi.dev/api/people/74/ film_url=https://swapi.dev/api/films/5/\n",
      "Inserting into people_films: person_url=https://swapi.dev/api/people/75/ film_url=https://swapi.dev/api/films/5/\n",
      "Inserting into people_films: person_url=https://swapi.dev/api/people/75/ film_url=https://swapi.dev/api/films/6/\n",
      "Inserting into people_films: person_url=https://swapi.dev/api/people/76/ film_url=https://swapi.dev/api/films/5/\n",
      "Inserting into people_films: person_url=https://swapi.dev/api/people/77/ film_url=https://swapi.dev/api/films/5/\n",
      "Inserting into people_films: person_url=https://swapi.dev/api/people/78/ film_url=https://swapi.dev/api/films/5/\n",
      "Inserting into people_films: person_url=https://swapi.dev/api/people/78/ film_url=https://swapi.dev/api/films/6/\n",
      "Inserting into people_films: person_url=https://swapi.dev/api/people/79/ film_url=https://swapi.dev/api/films/6/\n",
      "Inserting into people_films: person_url=https://swapi.dev/api/people/80/ film_url=https://swapi.dev/api/films/6/\n",
      "Inserting into people_films: person_url=https://swapi.dev/api/people/81/ film_url=https://swapi.dev/api/films/1/\n",
      "Inserting into people_films: person_url=https://swapi.dev/api/people/81/ film_url=https://swapi.dev/api/films/6/\n",
      "Inserting into people_films: person_url=https://swapi.dev/api/people/82/ film_url=https://swapi.dev/api/films/5/\n",
      "Inserting into people_films: person_url=https://swapi.dev/api/people/82/ film_url=https://swapi.dev/api/films/6/\n",
      "Inserting into people_films: person_url=https://swapi.dev/api/people/83/ film_url=https://swapi.dev/api/films/6/\n",
      "Inserting into people_species: person_url=https://swapi.dev/api/people/2/ species_url=https://swapi.dev/api/species/2/\n",
      "Inserting into people_species: person_url=https://swapi.dev/api/people/3/ species_url=https://swapi.dev/api/species/2/\n",
      "Inserting into people_species: person_url=https://swapi.dev/api/people/8/ species_url=https://swapi.dev/api/species/2/\n",
      "Inserting into people_species: person_url=https://swapi.dev/api/people/13/ species_url=https://swapi.dev/api/species/3/\n",
      "Inserting into people_species: person_url=https://swapi.dev/api/people/15/ species_url=https://swapi.dev/api/species/4/\n",
      "Inserting into people_species: person_url=https://swapi.dev/api/people/16/ species_url=https://swapi.dev/api/species/5/\n",
      "Inserting into people_species: person_url=https://swapi.dev/api/people/20/ species_url=https://swapi.dev/api/species/6/\n",
      "Inserting into people_species: person_url=https://swapi.dev/api/people/23/ species_url=https://swapi.dev/api/species/2/\n",
      "Inserting into people_species: person_url=https://swapi.dev/api/people/24/ species_url=https://swapi.dev/api/species/7/\n",
      "Inserting into people_species: person_url=https://swapi.dev/api/people/27/ species_url=https://swapi.dev/api/species/8/\n",
      "Inserting into people_species: person_url=https://swapi.dev/api/people/30/ species_url=https://swapi.dev/api/species/9/\n",
      "Inserting into people_species: person_url=https://swapi.dev/api/people/31/ species_url=https://swapi.dev/api/species/10/\n",
      "Inserting into people_species: person_url=https://swapi.dev/api/people/33/ species_url=https://swapi.dev/api/species/11/\n",
      "Inserting into people_species: person_url=https://swapi.dev/api/people/36/ species_url=https://swapi.dev/api/species/12/\n",
      "Inserting into people_species: person_url=https://swapi.dev/api/people/37/ species_url=https://swapi.dev/api/species/12/\n",
      "Inserting into people_species: person_url=https://swapi.dev/api/people/38/ species_url=https://swapi.dev/api/species/12/\n",
      "Inserting into people_species: person_url=https://swapi.dev/api/people/40/ species_url=https://swapi.dev/api/species/13/\n",
      "Inserting into people_species: person_url=https://swapi.dev/api/people/41/ species_url=https://swapi.dev/api/species/14/\n",
      "Inserting into people_species: person_url=https://swapi.dev/api/people/44/ species_url=https://swapi.dev/api/species/22/\n",
      "Inserting into people_species: person_url=https://swapi.dev/api/people/45/ species_url=https://swapi.dev/api/species/15/\n",
      "Inserting into people_species: person_url=https://swapi.dev/api/people/46/ species_url=https://swapi.dev/api/species/15/\n",
      "Inserting into people_species: person_url=https://swapi.dev/api/people/47/ species_url=https://swapi.dev/api/species/16/\n",
      "Inserting into people_species: person_url=https://swapi.dev/api/people/48/ species_url=https://swapi.dev/api/species/17/\n",
      "Inserting into people_species: person_url=https://swapi.dev/api/people/49/ species_url=https://swapi.dev/api/species/18/\n",
      "Inserting into people_species: person_url=https://swapi.dev/api/people/50/ species_url=https://swapi.dev/api/species/19/\n",
      "Inserting into people_species: person_url=https://swapi.dev/api/people/52/ species_url=https://swapi.dev/api/species/20/\n",
      "Inserting into people_species: person_url=https://swapi.dev/api/people/53/ species_url=https://swapi.dev/api/species/21/\n",
      "Inserting into people_species: person_url=https://swapi.dev/api/people/54/ species_url=https://swapi.dev/api/species/22/\n",
      "Inserting into people_species: person_url=https://swapi.dev/api/people/55/ species_url=https://swapi.dev/api/species/23/\n",
      "Inserting into people_species: person_url=https://swapi.dev/api/people/56/ species_url=https://swapi.dev/api/species/24/\n",
      "Inserting into people_species: person_url=https://swapi.dev/api/people/57/ species_url=https://swapi.dev/api/species/25/\n",
      "Inserting into people_species: person_url=https://swapi.dev/api/people/58/ species_url=https://swapi.dev/api/species/26/\n",
      "Inserting into people_species: person_url=https://swapi.dev/api/people/59/ species_url=https://swapi.dev/api/species/27/\n",
      "Inserting into people_species: person_url=https://swapi.dev/api/people/63/ species_url=https://swapi.dev/api/species/28/\n",
      "Inserting into people_species: person_url=https://swapi.dev/api/people/64/ species_url=https://swapi.dev/api/species/29/\n",
      "Inserting into people_species: person_url=https://swapi.dev/api/people/65/ species_url=https://swapi.dev/api/species/29/\n",
      "Inserting into people_species: person_url=https://swapi.dev/api/people/66/ species_url=https://swapi.dev/api/species/1/\n",
      "Inserting into people_species: person_url=https://swapi.dev/api/people/67/ species_url=https://swapi.dev/api/species/1/\n",
      "Inserting into people_species: person_url=https://swapi.dev/api/people/68/ species_url=https://swapi.dev/api/species/1/\n",
      "Inserting into people_species: person_url=https://swapi.dev/api/people/70/ species_url=https://swapi.dev/api/species/30/\n",
      "Inserting into people_species: person_url=https://swapi.dev/api/people/71/ species_url=https://swapi.dev/api/species/31/\n",
      "Inserting into people_species: person_url=https://swapi.dev/api/people/72/ species_url=https://swapi.dev/api/species/32/\n",
      "Inserting into people_species: person_url=https://swapi.dev/api/people/73/ species_url=https://swapi.dev/api/species/32/\n",
      "Inserting into people_species: person_url=https://swapi.dev/api/people/74/ species_url=https://swapi.dev/api/species/1/\n",
      "Inserting into people_species: person_url=https://swapi.dev/api/people/76/ species_url=https://swapi.dev/api/species/33/\n",
      "Inserting into people_species: person_url=https://swapi.dev/api/people/77/ species_url=https://swapi.dev/api/species/34/\n",
      "Inserting into people_species: person_url=https://swapi.dev/api/people/78/ species_url=https://swapi.dev/api/species/35/\n",
      "Inserting into people_species: person_url=https://swapi.dev/api/people/79/ species_url=https://swapi.dev/api/species/36/\n",
      "Inserting into people_species: person_url=https://swapi.dev/api/people/80/ species_url=https://swapi.dev/api/species/3/\n",
      "Inserting into people_species: person_url=https://swapi.dev/api/people/83/ species_url=https://swapi.dev/api/species/37/\n",
      "Inserting into people_starships: person_url=https://swapi.dev/api/people/1/ starship_url=https://swapi.dev/api/starships/12/\n",
      "Inserting into people_starships: person_url=https://swapi.dev/api/people/1/ starship_url=https://swapi.dev/api/starships/22/\n",
      "Inserting into people_starships: person_url=https://swapi.dev/api/people/4/ starship_url=https://swapi.dev/api/starships/13/\n",
      "Inserting into people_starships: person_url=https://swapi.dev/api/people/9/ starship_url=https://swapi.dev/api/starships/12/\n",
      "Inserting into people_starships: person_url=https://swapi.dev/api/people/10/ starship_url=https://swapi.dev/api/starships/48/\n",
      "Inserting into people_starships: person_url=https://swapi.dev/api/people/10/ starship_url=https://swapi.dev/api/starships/59/\n",
      "Inserting into people_starships: person_url=https://swapi.dev/api/people/10/ starship_url=https://swapi.dev/api/starships/64/\n",
      "Inserting into people_starships: person_url=https://swapi.dev/api/people/10/ starship_url=https://swapi.dev/api/starships/65/\n",
      "Inserting into people_starships: person_url=https://swapi.dev/api/people/10/ starship_url=https://swapi.dev/api/starships/74/\n",
      "Inserting into people_starships: person_url=https://swapi.dev/api/people/11/ starship_url=https://swapi.dev/api/starships/39/\n",
      "Inserting into people_starships: person_url=https://swapi.dev/api/people/11/ starship_url=https://swapi.dev/api/starships/59/\n",
      "Inserting into people_starships: person_url=https://swapi.dev/api/people/11/ starship_url=https://swapi.dev/api/starships/65/\n",
      "Inserting into people_starships: person_url=https://swapi.dev/api/people/13/ starship_url=https://swapi.dev/api/starships/10/\n",
      "Inserting into people_starships: person_url=https://swapi.dev/api/people/13/ starship_url=https://swapi.dev/api/starships/22/\n",
      "Inserting into people_starships: person_url=https://swapi.dev/api/people/14/ starship_url=https://swapi.dev/api/starships/10/\n",
      "Inserting into people_starships: person_url=https://swapi.dev/api/people/14/ starship_url=https://swapi.dev/api/starships/22/\n",
      "Inserting into people_starships: person_url=https://swapi.dev/api/people/18/ starship_url=https://swapi.dev/api/starships/12/\n",
      "Inserting into people_starships: person_url=https://swapi.dev/api/people/19/ starship_url=https://swapi.dev/api/starships/12/\n",
      "Inserting into people_starships: person_url=https://swapi.dev/api/people/22/ starship_url=https://swapi.dev/api/starships/21/\n",
      "Inserting into people_starships: person_url=https://swapi.dev/api/people/25/ starship_url=https://swapi.dev/api/starships/10/\n",
      "Inserting into people_starships: person_url=https://swapi.dev/api/people/29/ starship_url=https://swapi.dev/api/starships/28/\n",
      "Inserting into people_starships: person_url=https://swapi.dev/api/people/31/ starship_url=https://swapi.dev/api/starships/10/\n",
      "Inserting into people_starships: person_url=https://swapi.dev/api/people/35/ starship_url=https://swapi.dev/api/starships/39/\n",
      "Inserting into people_starships: person_url=https://swapi.dev/api/people/35/ starship_url=https://swapi.dev/api/starships/49/\n",
      "Inserting into people_starships: person_url=https://swapi.dev/api/people/35/ starship_url=https://swapi.dev/api/starships/64/\n",
      "Inserting into people_starships: person_url=https://swapi.dev/api/people/39/ starship_url=https://swapi.dev/api/starships/40/\n",
      "Inserting into people_starships: person_url=https://swapi.dev/api/people/44/ starship_url=https://swapi.dev/api/starships/41/\n",
      "Inserting into people_starships: person_url=https://swapi.dev/api/people/58/ starship_url=https://swapi.dev/api/starships/48/\n",
      "Inserting into people_starships: person_url=https://swapi.dev/api/people/60/ starship_url=https://swapi.dev/api/starships/39/\n",
      "Inserting into people_starships: person_url=https://swapi.dev/api/people/79/ starship_url=https://swapi.dev/api/starships/74/\n",
      "Inserting into people_vehicles: person_url=https://swapi.dev/api/people/1/ vehicle_url=https://swapi.dev/api/vehicles/14/\n",
      "Inserting into people_vehicles: person_url=https://swapi.dev/api/people/1/ vehicle_url=https://swapi.dev/api/vehicles/30/\n",
      "Inserting into people_vehicles: person_url=https://swapi.dev/api/people/5/ vehicle_url=https://swapi.dev/api/vehicles/30/\n",
      "Inserting into people_vehicles: person_url=https://swapi.dev/api/people/10/ vehicle_url=https://swapi.dev/api/vehicles/38/\n",
      "Inserting into people_vehicles: person_url=https://swapi.dev/api/people/11/ vehicle_url=https://swapi.dev/api/vehicles/44/\n",
      "Inserting into people_vehicles: person_url=https://swapi.dev/api/people/11/ vehicle_url=https://swapi.dev/api/vehicles/46/\n",
      "Inserting into people_vehicles: person_url=https://swapi.dev/api/people/13/ vehicle_url=https://swapi.dev/api/vehicles/19/\n",
      "Inserting into people_vehicles: person_url=https://swapi.dev/api/people/18/ vehicle_url=https://swapi.dev/api/vehicles/14/\n",
      "Inserting into people_vehicles: person_url=https://swapi.dev/api/people/32/ vehicle_url=https://swapi.dev/api/vehicles/38/\n",
      "Inserting into people_vehicles: person_url=https://swapi.dev/api/people/44/ vehicle_url=https://swapi.dev/api/vehicles/42/\n",
      "Inserting into people_vehicles: person_url=https://swapi.dev/api/people/67/ vehicle_url=https://swapi.dev/api/vehicles/55/\n",
      "Inserting into people_vehicles: person_url=https://swapi.dev/api/people/70/ vehicle_url=https://swapi.dev/api/vehicles/45/\n",
      "Inserting into people_vehicles: person_url=https://swapi.dev/api/people/79/ vehicle_url=https://swapi.dev/api/vehicles/60/\n",
      "Inserting relationship data for films...\n",
      "Inserting into films_species: film_url=https://swapi.dev/api/films/1/ species_url=https://swapi.dev/api/species/1/\n",
      "Inserting into films_species: film_url=https://swapi.dev/api/films/1/ species_url=https://swapi.dev/api/species/2/\n",
      "Inserting into films_species: film_url=https://swapi.dev/api/films/1/ species_url=https://swapi.dev/api/species/3/\n",
      "Inserting into films_species: film_url=https://swapi.dev/api/films/1/ species_url=https://swapi.dev/api/species/4/\n",
      "Inserting into films_species: film_url=https://swapi.dev/api/films/1/ species_url=https://swapi.dev/api/species/5/\n",
      "Inserting into films_species: film_url=https://swapi.dev/api/films/2/ species_url=https://swapi.dev/api/species/1/\n",
      "Inserting into films_species: film_url=https://swapi.dev/api/films/2/ species_url=https://swapi.dev/api/species/2/\n",
      "Inserting into films_species: film_url=https://swapi.dev/api/films/2/ species_url=https://swapi.dev/api/species/3/\n",
      "Inserting into films_species: film_url=https://swapi.dev/api/films/2/ species_url=https://swapi.dev/api/species/6/\n",
      "Inserting into films_species: film_url=https://swapi.dev/api/films/2/ species_url=https://swapi.dev/api/species/7/\n",
      "Inserting into films_species: film_url=https://swapi.dev/api/films/3/ species_url=https://swapi.dev/api/species/1/\n",
      "Inserting into films_species: film_url=https://swapi.dev/api/films/3/ species_url=https://swapi.dev/api/species/2/\n",
      "Inserting into films_species: film_url=https://swapi.dev/api/films/3/ species_url=https://swapi.dev/api/species/3/\n",
      "Inserting into films_species: film_url=https://swapi.dev/api/films/3/ species_url=https://swapi.dev/api/species/5/\n",
      "Inserting into films_species: film_url=https://swapi.dev/api/films/3/ species_url=https://swapi.dev/api/species/6/\n",
      "Inserting into films_species: film_url=https://swapi.dev/api/films/3/ species_url=https://swapi.dev/api/species/8/\n",
      "Inserting into films_species: film_url=https://swapi.dev/api/films/3/ species_url=https://swapi.dev/api/species/9/\n",
      "Inserting into films_species: film_url=https://swapi.dev/api/films/3/ species_url=https://swapi.dev/api/species/10/\n",
      "Inserting into films_species: film_url=https://swapi.dev/api/films/3/ species_url=https://swapi.dev/api/species/15/\n",
      "Inserting into films_species: film_url=https://swapi.dev/api/films/4/ species_url=https://swapi.dev/api/species/1/\n",
      "Inserting into films_species: film_url=https://swapi.dev/api/films/4/ species_url=https://swapi.dev/api/species/2/\n",
      "Inserting into films_species: film_url=https://swapi.dev/api/films/4/ species_url=https://swapi.dev/api/species/6/\n",
      "Inserting into films_species: film_url=https://swapi.dev/api/films/4/ species_url=https://swapi.dev/api/species/11/\n",
      "Inserting into films_species: film_url=https://swapi.dev/api/films/4/ species_url=https://swapi.dev/api/species/12/\n",
      "Inserting into films_species: film_url=https://swapi.dev/api/films/4/ species_url=https://swapi.dev/api/species/13/\n",
      "Inserting into films_species: film_url=https://swapi.dev/api/films/4/ species_url=https://swapi.dev/api/species/14/\n",
      "Inserting into films_species: film_url=https://swapi.dev/api/films/4/ species_url=https://swapi.dev/api/species/15/\n",
      "Inserting into films_species: film_url=https://swapi.dev/api/films/4/ species_url=https://swapi.dev/api/species/16/\n",
      "Inserting into films_species: film_url=https://swapi.dev/api/films/4/ species_url=https://swapi.dev/api/species/17/\n",
      "Inserting into films_species: film_url=https://swapi.dev/api/films/4/ species_url=https://swapi.dev/api/species/18/\n",
      "Inserting into films_species: film_url=https://swapi.dev/api/films/4/ species_url=https://swapi.dev/api/species/19/\n",
      "Inserting into films_species: film_url=https://swapi.dev/api/films/4/ species_url=https://swapi.dev/api/species/20/\n",
      "Inserting into films_species: film_url=https://swapi.dev/api/films/4/ species_url=https://swapi.dev/api/species/21/\n",
      "Inserting into films_species: film_url=https://swapi.dev/api/films/4/ species_url=https://swapi.dev/api/species/22/\n",
      "Inserting into films_species: film_url=https://swapi.dev/api/films/4/ species_url=https://swapi.dev/api/species/23/\n",
      "Inserting into films_species: film_url=https://swapi.dev/api/films/4/ species_url=https://swapi.dev/api/species/24/\n",
      "Inserting into films_species: film_url=https://swapi.dev/api/films/4/ species_url=https://swapi.dev/api/species/25/\n",
      "Inserting into films_species: film_url=https://swapi.dev/api/films/4/ species_url=https://swapi.dev/api/species/26/\n",
      "Inserting into films_species: film_url=https://swapi.dev/api/films/4/ species_url=https://swapi.dev/api/species/27/\n",
      "Inserting into films_species: film_url=https://swapi.dev/api/films/5/ species_url=https://swapi.dev/api/species/1/\n",
      "Inserting into films_species: film_url=https://swapi.dev/api/films/5/ species_url=https://swapi.dev/api/species/2/\n",
      "Inserting into films_species: film_url=https://swapi.dev/api/films/5/ species_url=https://swapi.dev/api/species/6/\n",
      "Inserting into films_species: film_url=https://swapi.dev/api/films/5/ species_url=https://swapi.dev/api/species/12/\n",
      "Inserting into films_species: film_url=https://swapi.dev/api/films/5/ species_url=https://swapi.dev/api/species/13/\n",
      "Inserting into films_species: film_url=https://swapi.dev/api/films/5/ species_url=https://swapi.dev/api/species/15/\n",
      "Inserting into films_species: film_url=https://swapi.dev/api/films/5/ species_url=https://swapi.dev/api/species/28/\n",
      "Inserting into films_species: film_url=https://swapi.dev/api/films/5/ species_url=https://swapi.dev/api/species/29/\n",
      "Inserting into films_species: film_url=https://swapi.dev/api/films/5/ species_url=https://swapi.dev/api/species/30/\n",
      "Inserting into films_species: film_url=https://swapi.dev/api/films/5/ species_url=https://swapi.dev/api/species/31/\n",
      "Inserting into films_species: film_url=https://swapi.dev/api/films/5/ species_url=https://swapi.dev/api/species/32/\n",
      "Inserting into films_species: film_url=https://swapi.dev/api/films/5/ species_url=https://swapi.dev/api/species/33/\n",
      "Inserting into films_species: film_url=https://swapi.dev/api/films/5/ species_url=https://swapi.dev/api/species/34/\n",
      "Inserting into films_species: film_url=https://swapi.dev/api/films/5/ species_url=https://swapi.dev/api/species/35/\n",
      "Inserting into films_species: film_url=https://swapi.dev/api/films/6/ species_url=https://swapi.dev/api/species/1/\n",
      "Inserting into films_species: film_url=https://swapi.dev/api/films/6/ species_url=https://swapi.dev/api/species/2/\n",
      "Inserting into films_species: film_url=https://swapi.dev/api/films/6/ species_url=https://swapi.dev/api/species/3/\n",
      "Inserting into films_species: film_url=https://swapi.dev/api/films/6/ species_url=https://swapi.dev/api/species/6/\n",
      "Inserting into films_species: film_url=https://swapi.dev/api/films/6/ species_url=https://swapi.dev/api/species/15/\n",
      "Inserting into films_species: film_url=https://swapi.dev/api/films/6/ species_url=https://swapi.dev/api/species/19/\n",
      "Inserting into films_species: film_url=https://swapi.dev/api/films/6/ species_url=https://swapi.dev/api/species/20/\n",
      "Inserting into films_species: film_url=https://swapi.dev/api/films/6/ species_url=https://swapi.dev/api/species/23/\n",
      "Inserting into films_species: film_url=https://swapi.dev/api/films/6/ species_url=https://swapi.dev/api/species/24/\n",
      "Inserting into films_species: film_url=https://swapi.dev/api/films/6/ species_url=https://swapi.dev/api/species/25/\n",
      "Inserting into films_species: film_url=https://swapi.dev/api/films/6/ species_url=https://swapi.dev/api/species/26/\n",
      "Inserting into films_species: film_url=https://swapi.dev/api/films/6/ species_url=https://swapi.dev/api/species/27/\n",
      "Inserting into films_species: film_url=https://swapi.dev/api/films/6/ species_url=https://swapi.dev/api/species/28/\n",
      "Inserting into films_species: film_url=https://swapi.dev/api/films/6/ species_url=https://swapi.dev/api/species/29/\n",
      "Inserting into films_species: film_url=https://swapi.dev/api/films/6/ species_url=https://swapi.dev/api/species/30/\n",
      "Inserting into films_species: film_url=https://swapi.dev/api/films/6/ species_url=https://swapi.dev/api/species/33/\n",
      "Inserting into films_species: film_url=https://swapi.dev/api/films/6/ species_url=https://swapi.dev/api/species/34/\n",
      "Inserting into films_species: film_url=https://swapi.dev/api/films/6/ species_url=https://swapi.dev/api/species/35/\n",
      "Inserting into films_species: film_url=https://swapi.dev/api/films/6/ species_url=https://swapi.dev/api/species/36/\n",
      "Inserting into films_species: film_url=https://swapi.dev/api/films/6/ species_url=https://swapi.dev/api/species/37/\n",
      "Inserting into films_starships: film_url=https://swapi.dev/api/films/1/ starship_url=https://swapi.dev/api/starships/2/\n",
      "Inserting into films_starships: film_url=https://swapi.dev/api/films/1/ starship_url=https://swapi.dev/api/starships/3/\n",
      "Inserting into films_starships: film_url=https://swapi.dev/api/films/1/ starship_url=https://swapi.dev/api/starships/5/\n",
      "Inserting into films_starships: film_url=https://swapi.dev/api/films/1/ starship_url=https://swapi.dev/api/starships/9/\n",
      "Inserting into films_starships: film_url=https://swapi.dev/api/films/1/ starship_url=https://swapi.dev/api/starships/10/\n",
      "Inserting into films_starships: film_url=https://swapi.dev/api/films/1/ starship_url=https://swapi.dev/api/starships/11/\n",
      "Inserting into films_starships: film_url=https://swapi.dev/api/films/1/ starship_url=https://swapi.dev/api/starships/12/\n",
      "Inserting into films_starships: film_url=https://swapi.dev/api/films/1/ starship_url=https://swapi.dev/api/starships/13/\n",
      "Inserting into films_starships: film_url=https://swapi.dev/api/films/2/ starship_url=https://swapi.dev/api/starships/3/\n",
      "Inserting into films_starships: film_url=https://swapi.dev/api/films/2/ starship_url=https://swapi.dev/api/starships/10/\n",
      "Inserting into films_starships: film_url=https://swapi.dev/api/films/2/ starship_url=https://swapi.dev/api/starships/11/\n",
      "Inserting into films_starships: film_url=https://swapi.dev/api/films/2/ starship_url=https://swapi.dev/api/starships/12/\n",
      "Inserting into films_starships: film_url=https://swapi.dev/api/films/2/ starship_url=https://swapi.dev/api/starships/15/\n",
      "Inserting into films_starships: film_url=https://swapi.dev/api/films/2/ starship_url=https://swapi.dev/api/starships/17/\n",
      "Inserting into films_starships: film_url=https://swapi.dev/api/films/2/ starship_url=https://swapi.dev/api/starships/21/\n",
      "Inserting into films_starships: film_url=https://swapi.dev/api/films/2/ starship_url=https://swapi.dev/api/starships/22/\n",
      "Inserting into films_starships: film_url=https://swapi.dev/api/films/2/ starship_url=https://swapi.dev/api/starships/23/\n",
      "Inserting into films_starships: film_url=https://swapi.dev/api/films/3/ starship_url=https://swapi.dev/api/starships/2/\n",
      "Inserting into films_starships: film_url=https://swapi.dev/api/films/3/ starship_url=https://swapi.dev/api/starships/3/\n",
      "Inserting into films_starships: film_url=https://swapi.dev/api/films/3/ starship_url=https://swapi.dev/api/starships/10/\n",
      "Inserting into films_starships: film_url=https://swapi.dev/api/films/3/ starship_url=https://swapi.dev/api/starships/11/\n",
      "Inserting into films_starships: film_url=https://swapi.dev/api/films/3/ starship_url=https://swapi.dev/api/starships/12/\n",
      "Inserting into films_starships: film_url=https://swapi.dev/api/films/3/ starship_url=https://swapi.dev/api/starships/15/\n",
      "Inserting into films_starships: film_url=https://swapi.dev/api/films/3/ starship_url=https://swapi.dev/api/starships/17/\n",
      "Inserting into films_starships: film_url=https://swapi.dev/api/films/3/ starship_url=https://swapi.dev/api/starships/22/\n",
      "Inserting into films_starships: film_url=https://swapi.dev/api/films/3/ starship_url=https://swapi.dev/api/starships/23/\n",
      "Inserting into films_starships: film_url=https://swapi.dev/api/films/3/ starship_url=https://swapi.dev/api/starships/27/\n",
      "Inserting into films_starships: film_url=https://swapi.dev/api/films/3/ starship_url=https://swapi.dev/api/starships/28/\n",
      "Inserting into films_starships: film_url=https://swapi.dev/api/films/3/ starship_url=https://swapi.dev/api/starships/29/\n",
      "Inserting into films_starships: film_url=https://swapi.dev/api/films/4/ starship_url=https://swapi.dev/api/starships/31/\n",
      "Inserting into films_starships: film_url=https://swapi.dev/api/films/4/ starship_url=https://swapi.dev/api/starships/32/\n",
      "Inserting into films_starships: film_url=https://swapi.dev/api/films/4/ starship_url=https://swapi.dev/api/starships/39/\n",
      "Inserting into films_starships: film_url=https://swapi.dev/api/films/4/ starship_url=https://swapi.dev/api/starships/40/\n",
      "Inserting into films_starships: film_url=https://swapi.dev/api/films/4/ starship_url=https://swapi.dev/api/starships/41/\n",
      "Inserting into films_starships: film_url=https://swapi.dev/api/films/5/ starship_url=https://swapi.dev/api/starships/21/\n",
      "Inserting into films_starships: film_url=https://swapi.dev/api/films/5/ starship_url=https://swapi.dev/api/starships/32/\n",
      "Inserting into films_starships: film_url=https://swapi.dev/api/films/5/ starship_url=https://swapi.dev/api/starships/39/\n",
      "Inserting into films_starships: film_url=https://swapi.dev/api/films/5/ starship_url=https://swapi.dev/api/starships/43/\n",
      "Inserting into films_starships: film_url=https://swapi.dev/api/films/5/ starship_url=https://swapi.dev/api/starships/47/\n",
      "Inserting into films_starships: film_url=https://swapi.dev/api/films/5/ starship_url=https://swapi.dev/api/starships/48/\n",
      "Inserting into films_starships: film_url=https://swapi.dev/api/films/5/ starship_url=https://swapi.dev/api/starships/49/\n",
      "Inserting into films_starships: film_url=https://swapi.dev/api/films/5/ starship_url=https://swapi.dev/api/starships/52/\n",
      "Inserting into films_starships: film_url=https://swapi.dev/api/films/5/ starship_url=https://swapi.dev/api/starships/58/\n",
      "Inserting into films_starships: film_url=https://swapi.dev/api/films/6/ starship_url=https://swapi.dev/api/starships/2/\n",
      "Inserting into films_starships: film_url=https://swapi.dev/api/films/6/ starship_url=https://swapi.dev/api/starships/32/\n",
      "Inserting into films_starships: film_url=https://swapi.dev/api/films/6/ starship_url=https://swapi.dev/api/starships/48/\n",
      "Inserting into films_starships: film_url=https://swapi.dev/api/films/6/ starship_url=https://swapi.dev/api/starships/59/\n",
      "Inserting into films_starships: film_url=https://swapi.dev/api/films/6/ starship_url=https://swapi.dev/api/starships/61/\n",
      "Inserting into films_starships: film_url=https://swapi.dev/api/films/6/ starship_url=https://swapi.dev/api/starships/63/\n",
      "Inserting into films_starships: film_url=https://swapi.dev/api/films/6/ starship_url=https://swapi.dev/api/starships/64/\n",
      "Inserting into films_starships: film_url=https://swapi.dev/api/films/6/ starship_url=https://swapi.dev/api/starships/65/\n",
      "Inserting into films_starships: film_url=https://swapi.dev/api/films/6/ starship_url=https://swapi.dev/api/starships/66/\n",
      "Inserting into films_starships: film_url=https://swapi.dev/api/films/6/ starship_url=https://swapi.dev/api/starships/68/\n",
      "Inserting into films_starships: film_url=https://swapi.dev/api/films/6/ starship_url=https://swapi.dev/api/starships/74/\n",
      "Inserting into films_starships: film_url=https://swapi.dev/api/films/6/ starship_url=https://swapi.dev/api/starships/75/\n",
      "Inserting into films_vehicles: film_url=https://swapi.dev/api/films/1/ vehicle_url=https://swapi.dev/api/vehicles/4/\n",
      "Inserting into films_vehicles: film_url=https://swapi.dev/api/films/1/ vehicle_url=https://swapi.dev/api/vehicles/6/\n",
      "Inserting into films_vehicles: film_url=https://swapi.dev/api/films/1/ vehicle_url=https://swapi.dev/api/vehicles/7/\n",
      "Inserting into films_vehicles: film_url=https://swapi.dev/api/films/1/ vehicle_url=https://swapi.dev/api/vehicles/8/\n",
      "Inserting into films_vehicles: film_url=https://swapi.dev/api/films/2/ vehicle_url=https://swapi.dev/api/vehicles/8/\n",
      "Inserting into films_vehicles: film_url=https://swapi.dev/api/films/2/ vehicle_url=https://swapi.dev/api/vehicles/14/\n",
      "Inserting into films_vehicles: film_url=https://swapi.dev/api/films/2/ vehicle_url=https://swapi.dev/api/vehicles/16/\n",
      "Inserting into films_vehicles: film_url=https://swapi.dev/api/films/2/ vehicle_url=https://swapi.dev/api/vehicles/18/\n",
      "Inserting into films_vehicles: film_url=https://swapi.dev/api/films/2/ vehicle_url=https://swapi.dev/api/vehicles/19/\n",
      "Inserting into films_vehicles: film_url=https://swapi.dev/api/films/2/ vehicle_url=https://swapi.dev/api/vehicles/20/\n",
      "Inserting into films_vehicles: film_url=https://swapi.dev/api/films/3/ vehicle_url=https://swapi.dev/api/vehicles/8/\n",
      "Inserting into films_vehicles: film_url=https://swapi.dev/api/films/3/ vehicle_url=https://swapi.dev/api/vehicles/16/\n",
      "Inserting into films_vehicles: film_url=https://swapi.dev/api/films/3/ vehicle_url=https://swapi.dev/api/vehicles/18/\n",
      "Inserting into films_vehicles: film_url=https://swapi.dev/api/films/3/ vehicle_url=https://swapi.dev/api/vehicles/19/\n",
      "Inserting into films_vehicles: film_url=https://swapi.dev/api/films/3/ vehicle_url=https://swapi.dev/api/vehicles/24/\n",
      "Inserting into films_vehicles: film_url=https://swapi.dev/api/films/3/ vehicle_url=https://swapi.dev/api/vehicles/25/\n",
      "Inserting into films_vehicles: film_url=https://swapi.dev/api/films/3/ vehicle_url=https://swapi.dev/api/vehicles/26/\n",
      "Inserting into films_vehicles: film_url=https://swapi.dev/api/films/3/ vehicle_url=https://swapi.dev/api/vehicles/30/\n",
      "Inserting into films_vehicles: film_url=https://swapi.dev/api/films/4/ vehicle_url=https://swapi.dev/api/vehicles/33/\n",
      "Inserting into films_vehicles: film_url=https://swapi.dev/api/films/4/ vehicle_url=https://swapi.dev/api/vehicles/34/\n",
      "Inserting into films_vehicles: film_url=https://swapi.dev/api/films/4/ vehicle_url=https://swapi.dev/api/vehicles/35/\n",
      "Inserting into films_vehicles: film_url=https://swapi.dev/api/films/4/ vehicle_url=https://swapi.dev/api/vehicles/36/\n",
      "Inserting into films_vehicles: film_url=https://swapi.dev/api/films/4/ vehicle_url=https://swapi.dev/api/vehicles/37/\n",
      "Inserting into films_vehicles: film_url=https://swapi.dev/api/films/4/ vehicle_url=https://swapi.dev/api/vehicles/38/\n",
      "Inserting into films_vehicles: film_url=https://swapi.dev/api/films/4/ vehicle_url=https://swapi.dev/api/vehicles/42/\n",
      "Inserting into films_vehicles: film_url=https://swapi.dev/api/films/5/ vehicle_url=https://swapi.dev/api/vehicles/4/\n",
      "Inserting into films_vehicles: film_url=https://swapi.dev/api/films/5/ vehicle_url=https://swapi.dev/api/vehicles/44/\n",
      "Inserting into films_vehicles: film_url=https://swapi.dev/api/films/5/ vehicle_url=https://swapi.dev/api/vehicles/45/\n",
      "Inserting into films_vehicles: film_url=https://swapi.dev/api/films/5/ vehicle_url=https://swapi.dev/api/vehicles/46/\n",
      "Inserting into films_vehicles: film_url=https://swapi.dev/api/films/5/ vehicle_url=https://swapi.dev/api/vehicles/50/\n",
      "Inserting into films_vehicles: film_url=https://swapi.dev/api/films/5/ vehicle_url=https://swapi.dev/api/vehicles/51/\n",
      "Inserting into films_vehicles: film_url=https://swapi.dev/api/films/5/ vehicle_url=https://swapi.dev/api/vehicles/53/\n",
      "Inserting into films_vehicles: film_url=https://swapi.dev/api/films/5/ vehicle_url=https://swapi.dev/api/vehicles/54/\n",
      "Inserting into films_vehicles: film_url=https://swapi.dev/api/films/5/ vehicle_url=https://swapi.dev/api/vehicles/55/\n",
      "Inserting into films_vehicles: film_url=https://swapi.dev/api/films/5/ vehicle_url=https://swapi.dev/api/vehicles/56/\n",
      "Inserting into films_vehicles: film_url=https://swapi.dev/api/films/5/ vehicle_url=https://swapi.dev/api/vehicles/57/\n",
      "Inserting into films_vehicles: film_url=https://swapi.dev/api/films/6/ vehicle_url=https://swapi.dev/api/vehicles/33/\n",
      "Inserting into films_vehicles: film_url=https://swapi.dev/api/films/6/ vehicle_url=https://swapi.dev/api/vehicles/50/\n",
      "Inserting into films_vehicles: film_url=https://swapi.dev/api/films/6/ vehicle_url=https://swapi.dev/api/vehicles/53/\n",
      "Inserting into films_vehicles: film_url=https://swapi.dev/api/films/6/ vehicle_url=https://swapi.dev/api/vehicles/56/\n",
      "Inserting into films_vehicles: film_url=https://swapi.dev/api/films/6/ vehicle_url=https://swapi.dev/api/vehicles/60/\n",
      "Inserting into films_vehicles: film_url=https://swapi.dev/api/films/6/ vehicle_url=https://swapi.dev/api/vehicles/62/\n",
      "Inserting into films_vehicles: film_url=https://swapi.dev/api/films/6/ vehicle_url=https://swapi.dev/api/vehicles/67/\n",
      "Inserting into films_vehicles: film_url=https://swapi.dev/api/films/6/ vehicle_url=https://swapi.dev/api/vehicles/69/\n",
      "Inserting into films_vehicles: film_url=https://swapi.dev/api/films/6/ vehicle_url=https://swapi.dev/api/vehicles/70/\n",
      "Inserting into films_vehicles: film_url=https://swapi.dev/api/films/6/ vehicle_url=https://swapi.dev/api/vehicles/71/\n",
      "Inserting into films_vehicles: film_url=https://swapi.dev/api/films/6/ vehicle_url=https://swapi.dev/api/vehicles/72/\n",
      "Inserting into films_vehicles: film_url=https://swapi.dev/api/films/6/ vehicle_url=https://swapi.dev/api/vehicles/73/\n",
      "Inserting into films_vehicles: film_url=https://swapi.dev/api/films/6/ vehicle_url=https://swapi.dev/api/vehicles/76/\n",
      "Inserting into films_planets: film_url=https://swapi.dev/api/films/1/ planet_url=https://swapi.dev/api/planets/1/\n",
      "Inserting into films_planets: film_url=https://swapi.dev/api/films/1/ planet_url=https://swapi.dev/api/planets/2/\n",
      "Inserting into films_planets: film_url=https://swapi.dev/api/films/1/ planet_url=https://swapi.dev/api/planets/3/\n",
      "Inserting into films_planets: film_url=https://swapi.dev/api/films/2/ planet_url=https://swapi.dev/api/planets/4/\n",
      "Inserting into films_planets: film_url=https://swapi.dev/api/films/2/ planet_url=https://swapi.dev/api/planets/5/\n",
      "Inserting into films_planets: film_url=https://swapi.dev/api/films/2/ planet_url=https://swapi.dev/api/planets/6/\n",
      "Inserting into films_planets: film_url=https://swapi.dev/api/films/2/ planet_url=https://swapi.dev/api/planets/27/\n",
      "Inserting into films_planets: film_url=https://swapi.dev/api/films/3/ planet_url=https://swapi.dev/api/planets/1/\n",
      "Inserting into films_planets: film_url=https://swapi.dev/api/films/3/ planet_url=https://swapi.dev/api/planets/5/\n",
      "Inserting into films_planets: film_url=https://swapi.dev/api/films/3/ planet_url=https://swapi.dev/api/planets/7/\n",
      "Inserting into films_planets: film_url=https://swapi.dev/api/films/3/ planet_url=https://swapi.dev/api/planets/8/\n",
      "Inserting into films_planets: film_url=https://swapi.dev/api/films/3/ planet_url=https://swapi.dev/api/planets/9/\n",
      "Inserting into films_planets: film_url=https://swapi.dev/api/films/4/ planet_url=https://swapi.dev/api/planets/1/\n",
      "Inserting into films_planets: film_url=https://swapi.dev/api/films/4/ planet_url=https://swapi.dev/api/planets/8/\n",
      "Inserting into films_planets: film_url=https://swapi.dev/api/films/4/ planet_url=https://swapi.dev/api/planets/9/\n",
      "Inserting into films_planets: film_url=https://swapi.dev/api/films/5/ planet_url=https://swapi.dev/api/planets/1/\n",
      "Inserting into films_planets: film_url=https://swapi.dev/api/films/5/ planet_url=https://swapi.dev/api/planets/8/\n",
      "Inserting into films_planets: film_url=https://swapi.dev/api/films/5/ planet_url=https://swapi.dev/api/planets/9/\n",
      "Inserting into films_planets: film_url=https://swapi.dev/api/films/5/ planet_url=https://swapi.dev/api/planets/10/\n",
      "Inserting into films_planets: film_url=https://swapi.dev/api/films/5/ planet_url=https://swapi.dev/api/planets/11/\n",
      "Inserting into films_planets: film_url=https://swapi.dev/api/films/6/ planet_url=https://swapi.dev/api/planets/1/\n",
      "Inserting into films_planets: film_url=https://swapi.dev/api/films/6/ planet_url=https://swapi.dev/api/planets/2/\n",
      "Inserting into films_planets: film_url=https://swapi.dev/api/films/6/ planet_url=https://swapi.dev/api/planets/5/\n",
      "Inserting into films_planets: film_url=https://swapi.dev/api/films/6/ planet_url=https://swapi.dev/api/planets/8/\n",
      "Inserting into films_planets: film_url=https://swapi.dev/api/films/6/ planet_url=https://swapi.dev/api/planets/9/\n",
      "Inserting into films_planets: film_url=https://swapi.dev/api/films/6/ planet_url=https://swapi.dev/api/planets/12/\n",
      "Inserting into films_planets: film_url=https://swapi.dev/api/films/6/ planet_url=https://swapi.dev/api/planets/13/\n",
      "Inserting into films_planets: film_url=https://swapi.dev/api/films/6/ planet_url=https://swapi.dev/api/planets/14/\n",
      "Inserting into films_planets: film_url=https://swapi.dev/api/films/6/ planet_url=https://swapi.dev/api/planets/15/\n",
      "Inserting into films_planets: film_url=https://swapi.dev/api/films/6/ planet_url=https://swapi.dev/api/planets/16/\n",
      "Inserting into films_planets: film_url=https://swapi.dev/api/films/6/ planet_url=https://swapi.dev/api/planets/17/\n",
      "Inserting into films_planets: film_url=https://swapi.dev/api/films/6/ planet_url=https://swapi.dev/api/planets/18/\n",
      "Inserting into films_planets: film_url=https://swapi.dev/api/films/6/ planet_url=https://swapi.dev/api/planets/19/\n",
      "Inserting relationship data for planets...\n",
      "Inserting relationship data for species...\n",
      "Inserting relationship data for vehicles...\n",
      "Inserting relationship data for starships...\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import psycopg2\n",
    "from psycopg2.extras import execute_values\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load environment variables from the .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Access the environment variables\n",
    "DB_PARAMS = {\n",
    "    \"dbname\": os.getenv(\"UNNORMALIZED_DB_NAME\"),\n",
    "    \"user\": os.getenv(\"DB_USER\"),\n",
    "    \"password\": os.getenv(\"DB_PASSWORD\"),\n",
    "    \"host\": os.getenv(\"DB_HOST\"),\n",
    "    \"port\": os.getenv(\"DB_PORT\")\n",
    "}\n",
    "\n",
    "BASE_URL = \"https://swapi.dev/api/\"\n",
    "SCHEMA_FILE = \"ddl/01_starwars_api_tables.sql\"\n",
    "\n",
    "try:\n",
    "    # Connect to the PostgreSQL database\n",
    "    conn = psycopg2.connect(**DB_PARAMS)\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    # Read the SQL schema file\n",
    "    with open(SCHEMA_FILE, \"r\", encoding=\"utf-8\") as file:\n",
    "        sql_script = file.read()\n",
    "\n",
    "    # Execute the SQL script\n",
    "    cursor.execute(sql_script)\n",
    "    conn.commit()\n",
    "\n",
    "    print(\"Star Wars Schema executed successfully.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error executing schema: {e}\")\n",
    "\n",
    "finally:\n",
    "    # Close the cursor and connection\n",
    "    if cursor:\n",
    "        cursor.close()\n",
    "    if conn:\n",
    "        conn.close()\n",
    "\n",
    "# Connect to PostgreSQL\n",
    "def get_db_connection():\n",
    "    return psycopg2.connect(**DB_PARAMS)\n",
    "\n",
    "# Fetch data from SWAPI with pagination\n",
    "def fetch_data(endpoint):\n",
    "    url = BASE_URL + endpoint\n",
    "    data = []\n",
    "    while url:\n",
    "        response = requests.get(url)\n",
    "        if response.status_code == 200:\n",
    "            json_data = response.json()\n",
    "            data.extend(json_data[\"results\"])\n",
    "            url = json_data[\"next\"]  # Pagination\n",
    "        else:\n",
    "            print(f\"Failed to fetch {endpoint}: {response.status_code}\")\n",
    "            break\n",
    "    return data\n",
    "\n",
    "# Insert data into database\n",
    "def insert_data(table, data, columns):\n",
    "    conn = get_db_connection()\n",
    "    cur = conn.cursor()\n",
    "\n",
    "    # Exclude relationship columns from the insert data\n",
    "    non_relationship_columns = [col for col in columns if col not in [\"films\", \"species\", \"starships\", \"vehicles\", \"planets\"]]\n",
    "\n",
    "    query = f\"\"\"\n",
    "        INSERT INTO {table} ({', '.join(non_relationship_columns)})\n",
    "        VALUES %s\n",
    "        ON CONFLICT DO NOTHING\n",
    "    \"\"\"\n",
    "    values = []\n",
    "    for record in data:\n",
    "        row = []\n",
    "        for col in non_relationship_columns:\n",
    "            if isinstance(record.get(col), list):\n",
    "                row.append(\"{\" + \",\".join(record.get(col, [])) + \"}\")  # Convert list to PostgreSQL array format\n",
    "            else:\n",
    "                row.append(record.get(col, None))\n",
    "        values.append(row)\n",
    "\n",
    "    try:\n",
    "        print(\"Inserting non-relationship data into table:\", table)\n",
    "        execute_values(cur, query, values)\n",
    "        conn.commit()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error inserting non-relationship data into {table}: {e}\")\n",
    "        conn.rollback()  # Rollback on error\n",
    "    finally:\n",
    "        cur.close()\n",
    "\n",
    "    return conn, table, data, columns\n",
    "\n",
    "def insert_relationship_data(conn, table, data, columns):\n",
    "    cur = conn.cursor()\n",
    "\n",
    "    # Phase 2: Insert relationship data for all tables\n",
    "    if \"films\" in columns:\n",
    "        for record in data:\n",
    "            for film_url in record.get(\"films\", []):\n",
    "                print(f\"Inserting into people_films: person_url={record['url']} film_url={film_url}\")\n",
    "                execute_values(cur, f\"\"\"\n",
    "                    INSERT INTO people_films (person_url, film_url)\n",
    "                    VALUES %s\n",
    "                \"\"\", [(record[\"url\"], film_url)])\n",
    "\n",
    "    # Insert relationships for \"species\"\n",
    "    if \"species\" in columns:\n",
    "        for record in data:\n",
    "            for species_url in record.get(\"species\", []):\n",
    "                if table == \"people\":  # Inserting into people_starships\n",
    "                    print(f\"Inserting into people_species: person_url={record['url']} species_url={species_url}\")\n",
    "                    execute_values(cur, f\"\"\"\n",
    "                        INSERT INTO people_species (person_url, species_url)\n",
    "                        VALUES %s\n",
    "                    \"\"\", [(record[\"url\"], species_url)])\n",
    "                elif table == \"films\":  # Inserting into films_starships\n",
    "                    print(f\"Inserting into films_species: film_url={record['url']} species_url={species_url}\")\n",
    "                    execute_values(cur, f\"\"\"\n",
    "                        INSERT INTO films_species (film_url, species_url)\n",
    "                        VALUES %s\n",
    "                    \"\"\", [(record[\"url\"], species_url)])\n",
    "\n",
    "    # Insert relationships for \"starships\"\n",
    "    if \"starships\" in columns:\n",
    "        for record in data:\n",
    "            for starship_url in record.get(\"starships\", []):\n",
    "                if table == \"people\":  # Inserting into people_starships\n",
    "                    print(f\"Inserting into people_starships: person_url={record['url']} starship_url={starship_url}\")\n",
    "                    execute_values(cur, f\"\"\"\n",
    "                        INSERT INTO people_starships (person_url, starship_url)\n",
    "                        VALUES %s\n",
    "                    \"\"\", [(record[\"url\"], starship_url)])\n",
    "                elif table == \"films\":  # Inserting into films_starships\n",
    "                    print(f\"Inserting into films_starships: film_url={record['url']} starship_url={starship_url}\")\n",
    "                    execute_values(cur, f\"\"\"\n",
    "                        INSERT INTO films_starships (film_url, starship_url)\n",
    "                        VALUES %s\n",
    "                    \"\"\", [(record[\"url\"], starship_url)])\n",
    "\n",
    "    # Insert relationships for \"vehicles\"\n",
    "    if \"vehicles\" in columns:\n",
    "        for record in data:\n",
    "            for vehicle_url in record.get(\"vehicles\", []):\n",
    "                if table == \"people\":  # Inserting into people_vehicles\n",
    "                    print(f\"Inserting into people_vehicles: person_url={record['url']} vehicle_url={vehicle_url}\")\n",
    "                    execute_values(cur, f\"\"\"\n",
    "                        INSERT INTO people_vehicles (person_url, vehicle_url)\n",
    "                        VALUES %s\n",
    "                    \"\"\", [(record[\"url\"], vehicle_url)])\n",
    "                elif table == \"films\":  # Inserting into films_vehicles\n",
    "                    print(f\"Inserting into films_vehicles: film_url={record['url']} vehicle_url={vehicle_url}\")\n",
    "                    execute_values(cur, f\"\"\"\n",
    "                        INSERT INTO films_vehicles (film_url, vehicle_url)\n",
    "                        VALUES %s\n",
    "                    \"\"\", [(record[\"url\"], vehicle_url)])\n",
    "\n",
    "    # Insert relationships for \"planets\"\n",
    "    if \"planets\" in columns:\n",
    "        for record in data:\n",
    "            for planet_url in record.get(\"planets\", []):\n",
    "                print(f\"Inserting into films_planets: film_url={record['url']} planet_url={planet_url}\")\n",
    "                execute_values(cur, f\"\"\"\n",
    "                    INSERT INTO films_planets (film_url, planet_url)\n",
    "                    VALUES %s\n",
    "                \"\"\", [(record[\"url\"], planet_url)])\n",
    "\n",
    "    # Commit the relationship data after all inserts\n",
    "    conn.commit()\n",
    "\n",
    "def fetch_data_by_url(url):\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    else:\n",
    "        print(f\"Failed to fetch {url}: {response.status_code}\")\n",
    "        return []\n",
    "\n",
    "# Fetch and store Star Wars data\n",
    "def main():\n",
    "    tables = {\n",
    "        \"people\": [\"name\", \"birth_year\", \"eye_color\", \"gender\", \"hair_color\", \"height\", \"mass\", \"skin_color\", \"homeworld\", \"url\", \"created\", \"edited\", \"films\", \"species\", \"starships\", \"vehicles\"],\n",
    "        \"films\": [\"title\", \"episode_id\", \"opening_crawl\", \"director\", \"producer\", \"release_date\", \"url\", \"created\", \"edited\", \"species\", \"starships\", \"vehicles\", \"planets\"],\n",
    "        \"planets\": [\"name\", \"diameter\", \"rotation_period\", \"orbital_period\", \"gravity\", \"population\", \"climate\", \"terrain\", \"surface_water\", \"url\", \"created\", \"edited\"],\n",
    "        \"species\": [\"name\", \"classification\", \"designation\", \"average_height\", \"average_lifespan\", \"eye_colors\", \"hair_colors\", \"skin_colors\", \"language\", \"homeworld\", \"url\", \"created\", \"edited\"],\n",
    "        \"vehicles\": [\"name\", \"model\", \"vehicle_class\", \"manufacturer\", \"length\", \"cost_in_credits\", \"crew\", \"passengers\", \"max_atmosphering_speed\", \"cargo_capacity\", \"consumables\", \"url\", \"created\", \"edited\"],\n",
    "        \"starships\": [\"name\", \"model\", \"starship_class\", \"manufacturer\", \"cost_in_credits\", \"length\", \"crew\", \"passengers\", \"max_atmosphering_speed\", \"hyperdrive_rating\", \"MGLT\", \"cargo_capacity\", \"consumables\", \"url\", \"created\", \"edited\"]\n",
    "    }\n",
    "    \n",
    "    # Phase 1: Insert non-relationship data for all tables\n",
    "    all_connections = []\n",
    "    for table, columns in tables.items():\n",
    "        print(f\"Fetching {table}...\")\n",
    "        data = fetch_data(table)\n",
    "        if data:\n",
    "            print(f\"Inserting {len(data)} records into {table}...\")\n",
    "            conn, table, data, columns = insert_data(table, data, columns)\n",
    "            all_connections.append((conn, table, data, columns))\n",
    "        else:\n",
    "            print(f\"No data fetched for {table}.\")\n",
    "\n",
    "    # Phase 2: Insert relationship data for all tables\n",
    "    for conn, table, data, columns in all_connections:\n",
    "        print(f\"Inserting relationship data for {table}...\")\n",
    "        insert_relationship_data(conn, table, data, columns)\n",
    "        conn.close()  # Close each connection after handling it\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first provide the DDL script used to create the tables required for the data from the OMDB API.\n",
    "\n",
    "This file is conatined in the `ddl` folder. Running this SQL code is NOT required as the following Python code handles it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "DROP TABLE IF EXISTS rating_providers CASCADE;\n",
    "DROP TABLE IF EXISTS ratings CASCADE;\n",
    "\n",
    "-- Table to store rating providers (e.g., Internet Movie Database, Rotten Tomatoes, Metacritic)\n",
    "CREATE TABLE rating_providers (\n",
    "    id SERIAL PRIMARY KEY,\n",
    "    name TEXT UNIQUE NOT NULL\n",
    ");\n",
    "\n",
    "-- Table to store movie ratings\n",
    "CREATE TABLE ratings (\n",
    "    id SERIAL PRIMARY KEY,\n",
    "    film_id SERIAL NOT NULL,\n",
    "    imdb_id TEXT NOT NULL,  -- IMDb ID for the movie\n",
    "    rating_provider_id INT NOT NULL,\n",
    "    rating_value TEXT NOT NULL,  -- Ratings may be in different formats (e.g., \"8.4/10\", \"94%\", \"78/100\")\n",
    "    FOREIGN KEY (rating_provider_id) REFERENCES rating_providers(id) ON DELETE CASCADE,\n",
    "    FOREIGN KEY (film_id) REFERENCES films(id) ON DELETE CASCADE\n",
    ");\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We continue with the Python script used to fetch data from the OMDB API.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import psycopg2\n",
    "from dotenv import load_dotenv\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load environment variables from the .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Database connection\n",
    "conn = psycopg2.connect(\n",
    "    dbname=os.getenv(\"UNNORMALIZED_DB_NAME\"),\n",
    "    user= os.getenv(\"DB_USER\"),\n",
    "    password=os.getenv(\"DB_PASSWORD\"),\n",
    "    host=os.getenv(\"DB_HOST\"),\n",
    "    port=os.getenv(\"DB_PORT\")\n",
    ")\n",
    "cur = conn.cursor()\n",
    "\n",
    "# OMDB API Key\n",
    "OMDB_BASE_URL = \"http://www.omdbapi.com/\"\n",
    "SCHEMA_FILE = \"ddl/02_omdb_tables.sql\"\n",
    "\n",
    "try:\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    # Read the SQL schema file\n",
    "    with open(SCHEMA_FILE, \"r\", encoding=\"utf-8\") as file:\n",
    "        sql_script = file.read()\n",
    "\n",
    "    # Execute the SQL script\n",
    "    cursor.execute(sql_script)\n",
    "    conn.commit()\n",
    "\n",
    "    print(\"OMDB Schema executed successfully.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error executing schema: {e}\")\n",
    "\n",
    "# Fetch all films (title and release year)\n",
    "print(\"Fetching films from database...\")\n",
    "cur.execute(\"SELECT id, title, release_date FROM films;\")\n",
    "films = cur.fetchall()\n",
    "print(f\"Retrieved {len(films)} films.\")\n",
    "\n",
    "# Function to get movie ratings from OMDB API\n",
    "def fetch_movie_ratings(title, year):\n",
    "    params = {\n",
    "        \"t\": title,\n",
    "        \"y\": year,\n",
    "        \"apikey\": os.getenv(\"OMDB_API_KEY\")\n",
    "    }\n",
    "    print(f\"Requesting OMDB API for {title} ({year})...\")\n",
    "    response = requests.get(OMDB_BASE_URL, params=params)\n",
    "    if response.status_code == 200:\n",
    "        print(f\"Response received for {title} ({year})\")\n",
    "        return response.json()\n",
    "    else:\n",
    "        print(f\"Failed to fetch data for {title} ({year}) - Status Code: {response.status_code}\")\n",
    "        return None\n",
    "\n",
    "# Insert rating providers\n",
    "print(\"Fetching existing rating providers...\")\n",
    "cur.execute(\"SELECT id, name FROM rating_providers;\")\n",
    "existing_providers = {name: id for id, name in cur.fetchall()}\n",
    "print(f\"Retrieved {len(existing_providers)} rating providers.\")\n",
    "\n",
    "# Process each film\n",
    "for film_id, title, release_date in films:\n",
    "    year = release_date.year if release_date else None\n",
    "    if not year:\n",
    "        print(f\"Skipping {title} due to missing release year.\")\n",
    "        continue\n",
    "\n",
    "    print(f\"Fetching ratings for {title} ({year})\")\n",
    "    movie_data = fetch_movie_ratings(title, year)\n",
    "    \n",
    "    if not movie_data or movie_data.get(\"Response\") == \"False\":\n",
    "        print(f\"No data found for {title} ({year}).\")\n",
    "        continue\n",
    "    \n",
    "    imdb_id = movie_data.get(\"imdbID\", \"N/A\")\n",
    "    print(f\"IMDb ID for {title} ({year}): {imdb_id}\")\n",
    "    \n",
    "    print(f\"Processing ratings for {title} ({year})\")\n",
    "    for rating in movie_data.get(\"Ratings\", []):\n",
    "        provider_name = rating[\"Source\"]\n",
    "        rating_value = rating[\"Value\"]\n",
    "        print(f\"Found rating: {provider_name} - {rating_value}\")\n",
    "        \n",
    "        # Ensure provider exists\n",
    "        if provider_name not in existing_providers:\n",
    "            print(f\"Inserting new rating provider: {provider_name}\")\n",
    "            cur.execute(\"INSERT INTO rating_providers (name) VALUES (%s) RETURNING id;\", (provider_name,))\n",
    "            provider_id = cur.fetchone()[0]\n",
    "            existing_providers[provider_name] = provider_id\n",
    "            conn.commit()\n",
    "        else:\n",
    "            provider_id = existing_providers[provider_name]\n",
    "        \n",
    "        # Insert rating with imdb_id\n",
    "        print(f\"Inserting rating for {title}: IMDb ID {imdb_id}, Provider ID {provider_id}, Value {rating_value}\")\n",
    "        cur.execute(\n",
    "            \"\"\"\n",
    "            INSERT INTO ratings (film_id, imdb_id, rating_provider_id, rating_value)\n",
    "            VALUES (%s, %s, %s, %s);\n",
    "            \"\"\",\n",
    "            (str(film_id), str(imdb_id), provider_id, rating_value)  # Ensuring correct types\n",
    "        )\n",
    "        conn.commit()\n",
    "\n",
    "print(\"Closing database connection...\")\n",
    "cur.close() \n",
    "conn.close()\n",
    "print(\"Ratings data populated successfully.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After downloading the TMDB Movie dataset from Kaggle, the following DDL script was used to create the tables necessary for the data to be collected from TMDB.\n",
    "\n",
    "This file is conatined in the `ddl` folder. Running this SQL code is NOT required as the following Python code handles it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "-- Delete the movie_metadata table if it exists\n",
    "DROP TABLE IF EXISTS movie_metadata;\n",
    "\n",
    "-- Table to store additional movie metadata (popularity and keywords)\n",
    "CREATE TABLE movie_metadata (\n",
    "    id INT PRIMARY KEY,\n",
    "    imdb_id TEXT UNIQUE NOT NULL,\n",
    "    popularity NUMERIC NOT NULL,\n",
    "    overview VARCHAR(1000),\n",
    "    runtime INTEGER,\n",
    "    keywords TEXT NOT NULL,\n",
    "    FOREIGN KEY (id) REFERENCES films(id) ON DELETE CASCADE\n",
    ");\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then use Python to fetch data from the `.csv` file downloaded and use the Star Wars movie data only.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import psycopg2\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load environment variables from the .env file\n",
    "load_dotenv()\n",
    "\n",
    "conn = psycopg2.connect(\n",
    "    dbname=os.getenv(\"UNNORMALIZED_DB_NAME\"),\n",
    "    user= os.getenv(\"DB_USER\"),\n",
    "    password=os.getenv(\"DB_PASSWORD\"),\n",
    "    host=os.getenv(\"DB_HOST\"),\n",
    "    port=os.getenv(\"DB_PORT\")\n",
    ")\n",
    "cur = conn.cursor()\n",
    "\n",
    "SCHEMA_FILE = \"ddl/03_tmdb_tables.sql\"\n",
    "\n",
    "try:\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    # Read the SQL schema file\n",
    "    with open(SCHEMA_FILE, \"r\", encoding=\"utf-8\") as file:\n",
    "        sql_script = file.read()\n",
    "\n",
    "    # Execute the SQL script\n",
    "    cursor.execute(sql_script)\n",
    "    conn.commit()\n",
    "\n",
    "    print(\"TMDB Schema executed successfully.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error executing schema: {e}\")\n",
    "\n",
    "# Path to the CSV file\n",
    "current_directory = os.getcwd()\n",
    "csv_file_path = os.path.join(current_directory, \"data\", \"tmdb_filtered_dataset.csv\")\n",
    "\n",
    "# Read IMDb IDs from ratings table and map them to film ids\n",
    "print(\"Fetching IMDb IDs and corresponding film ids from ratings table...\")\n",
    "cur.execute(\"\"\"\n",
    "    SELECT r.imdb_id, f.id \n",
    "    FROM ratings r\n",
    "    JOIN films f ON r.film_id = f.id;\n",
    "\"\"\")\n",
    "imdb_to_film_id = {row[0]: row[1] for row in cur.fetchall()}\n",
    "print(f\"Retrieved {len(imdb_to_film_id)} IMDb IDs and film IDs.\")\n",
    "\n",
    "# Read CSV and insert relevant data\n",
    "with open(csv_file_path, mode=\"r\", encoding=\"utf-8\") as csv_file:\n",
    "    reader = csv.DictReader(csv_file)\n",
    "\n",
    "    for row in reader:\n",
    "        imdb_id = row.get(\"imdb_id\")\n",
    "        popularity = row.get(\"popularity\")\n",
    "        keywords = row.get(\"keywords\")\n",
    "        overview = row.get(\"overview\")\n",
    "        runtime = row.get(\"runtime\")\n",
    "\n",
    "        # Skip rows with missing data or if imdb_id is not found in ratings table\n",
    "        if not imdb_id or imdb_id not in imdb_to_film_id or not popularity or not keywords:\n",
    "            continue\n",
    "\n",
    "        film_id = imdb_to_film_id[imdb_id]\n",
    "\n",
    "        print(f\"Inserting film_id {film_id} (IMDb ID: {imdb_id}) with popularity {popularity} and keywords {keywords}\")\n",
    "\n",
    "        # Insert into the movie_metadata table, ensuring the film_id is used as a reference\n",
    "        cur.execute(\n",
    "            \"\"\"\n",
    "            INSERT INTO movie_metadata (id, imdb_id, popularity, keywords, overview, runtime)\n",
    "            VALUES (%s, %s, %s, %s, %s, %s)\n",
    "            ON CONFLICT (id) DO NOTHING;\n",
    "            \"\"\",\n",
    "            (film_id, imdb_id, popularity, keywords, overview, runtime)\n",
    "        )\n",
    "        conn.commit()\n",
    "\n",
    "print(\"Closing database connection...\")\n",
    "cur.close()\n",
    "conn.close()\n",
    "print(\"Movie metadata populated successfully.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After retrieving the initial set of data, and investigating the overall structure of the unnormalized database, we will be using the following DDL script to structure the normalized dataset.\n",
    "\n",
    "This file is conatined in the `ddl` folder. Running this SQL code is NOT required as the following Python code handles it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "-- Drop tables if they exist\n",
    "DROP TABLE IF EXISTS people CASCADE;\n",
    "DROP TABLE IF EXISTS films CASCADE;\n",
    "DROP TABLE IF EXISTS starships CASCADE;\n",
    "DROP TABLE IF EXISTS vehicles CASCADE;\n",
    "DROP TABLE IF EXISTS species CASCADE;\n",
    "DROP TABLE IF EXISTS planets CASCADE;\n",
    "\n",
    "DROP TABLE IF EXISTS people_films CASCADE;\n",
    "DROP TABLE IF EXISTS people_species CASCADE;\n",
    "DROP TABLE IF EXISTS people_starships CASCADE;\n",
    "DROP TABLE IF EXISTS people_vehicles CASCADE;\n",
    "DROP TABLE IF EXISTS films_species CASCADE;\n",
    "DROP TABLE IF EXISTS films_starships CASCADE;\n",
    "DROP TABLE IF EXISTS films_vehicles CASCADE;\n",
    "DROP TABLE IF EXISTS films_planets CASCADE;\n",
    "\n",
    "DROP TABLE IF EXISTS rating_providers CASCADE;\n",
    "DROP TABLE IF EXISTS ratings CASCADE;\n",
    "\n",
    "DROP TABLE IF EXISTS keywords CASCADE;\n",
    "DROP TABLE IF EXISTS movie_metadata CASCADE;\n",
    "\n",
    "-- Create tables\n",
    "CREATE TABLE people (\n",
    "    id SERIAL PRIMARY KEY,\n",
    "    name VARCHAR(255) NOT NULL,\n",
    "    birth_year VARCHAR(20),\n",
    "    eye_color VARCHAR(50),\n",
    "    gender VARCHAR(20),\n",
    "    hair_color VARCHAR(50),\n",
    "    height VARCHAR(20),\n",
    "    mass VARCHAR(20),\n",
    "    skin_color VARCHAR(50),\n",
    "    homeworld VARCHAR(255),\n",
    "    url VARCHAR(255) UNIQUE NOT NULL,\n",
    "    created TIMESTAMP,\n",
    "    edited TIMESTAMP\n",
    ");\n",
    "\n",
    "CREATE TABLE films (\n",
    "    id SERIAL PRIMARY KEY,\n",
    "    title VARCHAR(255) NOT NULL,\n",
    "    episode_id INTEGER NOT NULL,\n",
    "    opening_crawl TEXT,\n",
    "    director VARCHAR(255),\n",
    "    producer VARCHAR(255),\n",
    "    release_date DATE,\n",
    "    imdb_id VARCHAR(50),  -- Added IMDb ID\n",
    "    overview VARCHAR(1000),\n",
    "    runtime INTEGER,\n",
    "    popularity NUMERIC,\n",
    "    url VARCHAR(255) UNIQUE NOT NULL,\n",
    "    created TIMESTAMP,\n",
    "    edited TIMESTAMP\n",
    ");\n",
    "\n",
    "CREATE TABLE starships (\n",
    "    id SERIAL PRIMARY KEY,\n",
    "    name VARCHAR(255) NOT NULL,\n",
    "    model VARCHAR(255),\n",
    "    starship_class VARCHAR(255),\n",
    "    manufacturer VARCHAR(255),\n",
    "    cost_in_credits VARCHAR(50),\n",
    "    length VARCHAR(50),\n",
    "    crew VARCHAR(50),\n",
    "    passengers VARCHAR(50),\n",
    "    max_atmosphering_speed VARCHAR(50),\n",
    "    hyperdrive_rating VARCHAR(50),\n",
    "    MGLT VARCHAR(50),\n",
    "    cargo_capacity VARCHAR(50),\n",
    "    consumables VARCHAR(255),\n",
    "    url VARCHAR(255) UNIQUE NOT NULL,\n",
    "    created TIMESTAMP,\n",
    "    edited TIMESTAMP\n",
    ");\n",
    "\n",
    "CREATE TABLE vehicles (\n",
    "    id SERIAL PRIMARY KEY,\n",
    "    name VARCHAR(255) NOT NULL,\n",
    "    model VARCHAR(255),\n",
    "    vehicle_class VARCHAR(255),\n",
    "    manufacturer VARCHAR(255),\n",
    "    length VARCHAR(50),\n",
    "    cost_in_credits VARCHAR(50),\n",
    "    crew VARCHAR(50),\n",
    "    passengers VARCHAR(50),\n",
    "    max_atmosphering_speed VARCHAR(50),\n",
    "    cargo_capacity VARCHAR(50),\n",
    "    consumables VARCHAR(255),\n",
    "    url VARCHAR(255) UNIQUE NOT NULL,\n",
    "    created TIMESTAMP,\n",
    "    edited TIMESTAMP\n",
    ");\n",
    "\n",
    "CREATE TABLE species (\n",
    "    id SERIAL PRIMARY KEY,\n",
    "    name VARCHAR(255) NOT NULL,\n",
    "    classification VARCHAR(255),\n",
    "    designation VARCHAR(50),\n",
    "    average_height VARCHAR(50),\n",
    "    average_lifespan VARCHAR(50),\n",
    "    eye_colors VARCHAR(255),\n",
    "    hair_colors VARCHAR(255),\n",
    "    skin_colors VARCHAR(255),\n",
    "    language VARCHAR(255),\n",
    "    homeworld VARCHAR(255),\n",
    "    url VARCHAR(255) UNIQUE NOT NULL,\n",
    "    created TIMESTAMP,\n",
    "    edited TIMESTAMP\n",
    ");\n",
    "\n",
    "CREATE TABLE planets (\n",
    "    id SERIAL PRIMARY KEY,\n",
    "    name VARCHAR(255) NOT NULL,\n",
    "    diameter VARCHAR(50),\n",
    "    rotation_period VARCHAR(50),\n",
    "    orbital_period VARCHAR(50),\n",
    "    gravity VARCHAR(50),\n",
    "    population VARCHAR(50),\n",
    "    climate VARCHAR(255),\n",
    "    terrain VARCHAR(255),\n",
    "    surface_water VARCHAR(50),\n",
    "    url VARCHAR(255) UNIQUE NOT NULL,\n",
    "    created TIMESTAMP,\n",
    "    edited TIMESTAMP\n",
    ");\n",
    "\n",
    "-- Relationship Tables for Many-to-Many Relationships with IDs\n",
    "CREATE TABLE people_films (\n",
    "    person_url VARCHAR(255) REFERENCES people(url) ON DELETE CASCADE,\n",
    "    film_url VARCHAR(255) REFERENCES films(url) ON DELETE CASCADE,\n",
    "    PRIMARY KEY (person_url, film_url)\n",
    ");\n",
    "\n",
    "CREATE TABLE people_species (\n",
    "    person_url VARCHAR(255) REFERENCES people(url) ON DELETE CASCADE,\n",
    "    species_url VARCHAR(255) REFERENCES species(url) ON DELETE CASCADE,\n",
    "    PRIMARY KEY (person_url, species_url)\n",
    ");\n",
    "\n",
    "CREATE TABLE people_starships (\n",
    "    person_url VARCHAR(255) REFERENCES people(url) ON DELETE CASCADE,\n",
    "    starship_url VARCHAR(255) REFERENCES starships(url) ON DELETE CASCADE,\n",
    "    PRIMARY KEY (person_url, starship_url)\n",
    ");\n",
    "\n",
    "CREATE TABLE people_vehicles (\n",
    "    person_url VARCHAR(255) REFERENCES people(url) ON DELETE CASCADE,\n",
    "    vehicle_url VARCHAR(255) REFERENCES vehicles(url) ON DELETE CASCADE,\n",
    "    PRIMARY KEY (person_url, vehicle_url)\n",
    ");\n",
    "\n",
    "CREATE TABLE films_species (\n",
    "    film_url VARCHAR(255) REFERENCES films(url) ON DELETE CASCADE,\n",
    "    species_url VARCHAR(255) REFERENCES species(url) ON DELETE CASCADE,\n",
    "    PRIMARY KEY (film_url, species_url)\n",
    ");\n",
    "\n",
    "CREATE TABLE films_starships (\n",
    "    film_url VARCHAR(255) REFERENCES films(url) ON DELETE CASCADE,\n",
    "    starship_url VARCHAR(255) REFERENCES starships(url) ON DELETE CASCADE,\n",
    "    PRIMARY KEY (film_url, starship_url)\n",
    ");\n",
    "\n",
    "CREATE TABLE films_vehicles (\n",
    "    film_url VARCHAR(255) REFERENCES films(url) ON DELETE CASCADE,\n",
    "    vehicle_url VARCHAR(255) REFERENCES vehicles(url) ON DELETE CASCADE,\n",
    "    PRIMARY KEY (film_url, vehicle_url)\n",
    ");\n",
    "\n",
    "CREATE TABLE films_planets (\n",
    "    film_url VARCHAR(255) REFERENCES films(url) ON DELETE CASCADE,\n",
    "    planet_url TEXT REFERENCES planets(url) ON DELETE CASCADE,\n",
    "    PRIMARY KEY (film_url, planet_url)\n",
    ");\n",
    "\n",
    "-- Table to store rating providers (e.g., Internet Movie Database, Rotten Tomatoes, Metacritic)\n",
    "CREATE TABLE rating_providers (\n",
    "    id SERIAL PRIMARY KEY,\n",
    "    name TEXT UNIQUE NOT NULL\n",
    ");\n",
    "\n",
    "-- Table to store movie ratings\n",
    "CREATE TABLE ratings (\n",
    "    id SERIAL PRIMARY KEY,\n",
    "    film_id INT NOT NULL,\n",
    "    rating_provider_id INT NOT NULL,\n",
    "    rating_value NUMERIC NOT NULL,  -- Rating value is now numeric (e.g., 8.4, 94, 78)\n",
    "    FOREIGN KEY (rating_provider_id) REFERENCES rating_providers(id) ON DELETE CASCADE,\n",
    "    FOREIGN KEY (film_id) REFERENCES films(id) ON DELETE CASCADE\n",
    ");\n",
    "\n",
    "-- Table to store keywords\n",
    "CREATE TABLE keywords (\n",
    "    id SERIAL PRIMARY KEY,\n",
    "    keyword TEXT UNIQUE NOT NULL\n",
    ");\n",
    "\n",
    "-- Table to store additional movie metadata\n",
    "CREATE TABLE movie_metadata (\n",
    "    id SERIAL PRIMARY KEY,\n",
    "    film_id INT NOT NULL,\n",
    "    keyword_id INT NOT NULL,\n",
    "    FOREIGN KEY (film_id) REFERENCES films(id) ON DELETE CASCADE,\n",
    "    FOREIGN KEY (keyword_id) REFERENCES keywords(id) ON DELETE CASCADE\n",
    ");\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We make use of batch queries and inserts to take data from our unnormalized database and place it into the normalized database, through Python.\n",
    "\n",
    "1. **Separated Entities into Dedicated Tables**\n",
    "\n",
    "   - Instead of storing all data in a single `films` table, individual tables were created for:\n",
    "     - `people`, `planets`, `starships`, `vehicles`, `species`.\n",
    "\n",
    "2. **Created Relationship (Junction) Tables**\n",
    "\n",
    "   - Many-to-many relationships were **extracted** into separate linking tables:\n",
    "     - `people_films`, `films_species`, `films_starships`, `films_vehicles`, etc.\n",
    "\n",
    "3. **Extracted Ratings into a Separate Table**\n",
    "\n",
    "   - `ratings` were moved to a new table with a **consistent rating scale** (0-100).\n",
    "   - `rating_providers` table was introduced to avoid repeating provider names.\n",
    "\n",
    "4. **Normalized Keywords for Movie Metadata**\n",
    "   - `keywords` were extracted into a separate table to avoid duplication.\n",
    "   - A linking table associates `films` with `keywords`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load environment variables from the .env file\n",
    "load_dotenv()\n",
    "\n",
    "starwars_db_conn = psycopg2.connect(\n",
    "    dbname=os.getenv(\"UNNORMALIZED_DB_NAME\"),\n",
    "    user= os.getenv(\"DB_USER\"),\n",
    "    password=os.getenv(\"DB_PASSWORD\"),\n",
    "    host=os.getenv(\"DB_HOST\"),\n",
    "    port=os.getenv(\"DB_PORT\")\n",
    ")\n",
    "\n",
    "normalized_db_conn = psycopg2.connect(\n",
    "    dbname=os.getenv(\"NORMALIZED_DB_NAME\"),\n",
    "    user= os.getenv(\"DB_USER\"),\n",
    "    password=os.getenv(\"DB_PASSWORD\"),\n",
    "    host=os.getenv(\"DB_HOST\"),\n",
    "    port=os.getenv(\"DB_PORT\")\n",
    ")\n",
    "\n",
    "SCHEMA_FILE = \"ddl/04_final_schema.sql\"\n",
    "\n",
    "try:\n",
    "    cursor = normalized_db_conn.cursor()\n",
    "\n",
    "    # Read the SQL schema file\n",
    "    with open(SCHEMA_FILE, \"r\", encoding=\"utf-8\") as file:\n",
    "        sql_script = file.read()\n",
    "\n",
    "    # Execute the SQL script\n",
    "    cursor.execute(sql_script)\n",
    "    normalized_db_conn.commit()\n",
    "\n",
    "    print(\"Normalized Schema executed successfully.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error executing schema: {e}\")\n",
    "\n",
    "# Create a cursor for both databases\n",
    "starwars_db_cursor = starwars_db_conn.cursor()\n",
    "normalized_db_cursor = normalized_db_conn.cursor()\n",
    "\n",
    "# ============================================================\n",
    "# PHASE 1: Migrating 'films' Data from starwars_db to normalized_starwars_db\n",
    "# ============================================================\n",
    "\n",
    "# Query to get data from the 'films' table and the 'popularity' from 'movie_metadata' in starwars_db\n",
    "starwars_db_cursor.execute(\"\"\"\n",
    "    SELECT \n",
    "        f.id, f.title, f.episode_id, f.opening_crawl, f.director, f.producer, \n",
    "        f.release_date, f.url, f.created, f.edited, m.popularity, m.imdb_id\n",
    "    FROM films f\n",
    "    LEFT JOIN movie_metadata m ON f.id = m.id\n",
    "\"\"\")\n",
    "\n",
    "# Fetch all rows from the query result\n",
    "films = starwars_db_cursor.fetchall()\n",
    "\n",
    "# Insert data into the 'films' table in normalized_starwars_db\n",
    "for film in films:\n",
    "    id, title, episode_id, opening_crawl, director, producer, release_date, url, created, edited, popularity, imdb_id = film\n",
    "    \n",
    "    # Prepare the SQL statement to insert into the normalized films table\n",
    "    insert_query = \"\"\"\n",
    "        INSERT INTO films (id, title, episode_id, opening_crawl, director, producer, \n",
    "                           release_date, url, created, edited, popularity, imdb_id)\n",
    "        VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Execute the insertion in the normalized_starwars_db\n",
    "    normalized_db_cursor.execute(insert_query, (id, title, episode_id, opening_crawl, director, producer, \n",
    "                                                release_date, url, created, edited, popularity, imdb_id))\n",
    "\n",
    "# Commit the transaction and close the connections\n",
    "normalized_db_conn.commit()\n",
    "\n",
    "# ============================================================\n",
    "# End of PHASE 1\n",
    "# ============================================================\n",
    "\n",
    "# ============================================================\n",
    "# PHASE 2: Migrating 'people', 'starships', 'vehicles', 'species', and 'planets' Data from starwars_db to normalized_starwars_db\n",
    "# ============================================================\n",
    "\n",
    "# People Table\n",
    "starwars_db_cursor.execute(\"SELECT id, name, birth_year, eye_color, gender, hair_color, height, mass, skin_color, homeworld, url, created, edited FROM people\")\n",
    "people = starwars_db_cursor.fetchall()\n",
    "for person in people:\n",
    "    id, name, birth_year, eye_color, gender, hair_color, height, mass, skin_color, homeworld, url, created, edited = person\n",
    "    insert_query = \"\"\"\n",
    "        INSERT INTO people (id, name, birth_year, eye_color, gender, hair_color, height, mass, skin_color, homeworld, url, created, edited)\n",
    "        VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\n",
    "    \"\"\"\n",
    "    normalized_db_cursor.execute(insert_query, (id, name, birth_year, eye_color, gender, hair_color, height, mass, skin_color, homeworld, url, created, edited))\n",
    "\n",
    "# Starships Table\n",
    "starwars_db_cursor.execute(\"SELECT id, name, model, starship_class, manufacturer, cost_in_credits, length, crew, passengers, max_atmosphering_speed, hyperdrive_rating, MGLT, cargo_capacity, consumables, url, created, edited FROM starships\")\n",
    "starships = starwars_db_cursor.fetchall()\n",
    "for starship in starships:\n",
    "    # Unpack the data into corresponding variables\n",
    "    id, name, model, starship_class, manufacturer, cost_in_credits, length, crew, passengers, max_atmosphering_speed, hyperdrive_rating, MGLT, cargo_capacity, consumables, url, created, edited = starship\n",
    "    \n",
    "    # Prepare the SQL statement to insert into the normalized starships table\n",
    "    insert_query = \"\"\"\n",
    "        INSERT INTO starships (id, name, model, starship_class, manufacturer, cost_in_credits, length, crew, passengers, max_atmosphering_speed, hyperdrive_rating, MGLT, cargo_capacity, consumables, url, created, edited)\n",
    "        VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Execute the insertion in the normalized_starwars_db\n",
    "    normalized_db_cursor.execute(insert_query, (id, name, model, starship_class, manufacturer, cost_in_credits, length, crew, passengers, max_atmosphering_speed, hyperdrive_rating, MGLT, cargo_capacity, consumables, url, created, edited))\n",
    "\n",
    "# Vehicles Table\n",
    "starwars_db_cursor.execute(\"SELECT id, name, model, vehicle_class, manufacturer, length, cost_in_credits, crew, passengers, max_atmosphering_speed, cargo_capacity, consumables, url, created, edited FROM vehicles\")\n",
    "vehicles = starwars_db_cursor.fetchall()\n",
    "for vehicle in vehicles:\n",
    "    id, name, model, vehicle_class, manufacturer, length, cost_in_credits, crew, passengers, max_atmosphering_speed, cargo_capacity, consumables, url, created, edited = vehicle\n",
    "    insert_query = \"\"\"\n",
    "        INSERT INTO vehicles (id, name, model, vehicle_class, manufacturer, length, cost_in_credits, crew, passengers, max_atmosphering_speed, cargo_capacity, consumables, url, created, edited)\n",
    "        VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\n",
    "    \"\"\"\n",
    "    normalized_db_cursor.execute(insert_query, (id, name, model, vehicle_class, manufacturer, length, cost_in_credits, crew, passengers, max_atmosphering_speed, cargo_capacity, consumables, url, created, edited))\n",
    "\n",
    "# Species Table\n",
    "starwars_db_cursor.execute(\"SELECT id, name, classification, designation, average_height, average_lifespan, eye_colors, hair_colors, skin_colors, language, homeworld, url, created, edited FROM species\")\n",
    "species = starwars_db_cursor.fetchall()\n",
    "for spec in species:\n",
    "    id, name, classification, designation, average_height, average_lifespan, eye_colors, hair_colors, skin_colors, language, homeworld, url, created, edited = spec\n",
    "    insert_query = \"\"\"\n",
    "        INSERT INTO species (id, name, classification, designation, average_height, average_lifespan, eye_colors, hair_colors, skin_colors, language, homeworld, url, created, edited)\n",
    "        VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\n",
    "    \"\"\"\n",
    "    normalized_db_cursor.execute(insert_query, (id, name, classification, designation, average_height, average_lifespan, eye_colors, hair_colors, skin_colors, language, homeworld, url, created, edited))\n",
    "\n",
    "# Planets Table\n",
    "starwars_db_cursor.execute(\"SELECT id, name, diameter, rotation_period, orbital_period, gravity, population, climate, terrain, surface_water, url, created, edited FROM planets\")\n",
    "planets = starwars_db_cursor.fetchall()\n",
    "for planet in planets:\n",
    "    id, name, diameter, rotation_period, orbital_period, gravity, population, climate, terrain, surface_water, url, created, edited = planet\n",
    "    insert_query = \"\"\"\n",
    "        INSERT INTO planets (id, name, diameter, rotation_period, orbital_period, gravity, population, climate, terrain, surface_water, url, created, edited)\n",
    "        VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\n",
    "    \"\"\"\n",
    "    normalized_db_cursor.execute(insert_query, (id, name, diameter, rotation_period, orbital_period, gravity, population, climate, terrain, surface_water, url, created, edited))\n",
    "\n",
    "# Commit the transaction\n",
    "normalized_db_conn.commit()\n",
    "\n",
    "# ============================================================\n",
    "# End of PHASE 2\n",
    "# ============================================================\n",
    "\n",
    "# ============================================================\n",
    "# PHASE 3: Migrating Relationships Data and Extracting IDs from URLs for Relationship Tables\n",
    "# ============================================================\n",
    "\n",
    "# People_Films Relationship\n",
    "starwars_db_cursor.execute(\"SELECT person_url, film_url FROM people_films\")\n",
    "people_films = starwars_db_cursor.fetchall()\n",
    "for person_url, film_url in people_films:\n",
    "    \n",
    "    insert_query = \"\"\"\n",
    "        INSERT INTO people_films (person_url, film_url)\n",
    "        VALUES (%s, %s)\n",
    "    \"\"\"\n",
    "    normalized_db_cursor.execute(insert_query, (person_url, film_url))\n",
    "\n",
    "# People_Species Relationship\n",
    "starwars_db_cursor.execute(\"SELECT person_url, species_url FROM people_species\")\n",
    "people_species = starwars_db_cursor.fetchall()\n",
    "for person_url, species_url in people_species:\n",
    "    \n",
    "    insert_query = \"\"\"\n",
    "        INSERT INTO people_species (person_url, species_url)\n",
    "        VALUES (%s, %s)\n",
    "    \"\"\"\n",
    "    normalized_db_cursor.execute(insert_query, (person_url, species_url))\n",
    "\n",
    "# People_Starships Relationship\n",
    "starwars_db_cursor.execute(\"SELECT person_url, starship_url FROM people_starships\")\n",
    "people_starships = starwars_db_cursor.fetchall()\n",
    "for person_url, starship_url in people_starships:\n",
    "    \n",
    "    insert_query = \"\"\"\n",
    "        INSERT INTO people_starships (person_url, starship_url)\n",
    "        VALUES (%s, %s)\n",
    "    \"\"\"\n",
    "    normalized_db_cursor.execute(insert_query, (person_url, starship_url))\n",
    "\n",
    "# People_Vehicles Relationship\n",
    "starwars_db_cursor.execute(\"SELECT person_url, vehicle_url FROM people_vehicles\")\n",
    "people_vehicles = starwars_db_cursor.fetchall()\n",
    "for person_url, vehicle_url in people_vehicles:\n",
    "    \n",
    "    insert_query = \"\"\"\n",
    "        INSERT INTO people_vehicles (person_url, vehicle_url)\n",
    "        VALUES (%s, %s)\n",
    "    \"\"\"\n",
    "    normalized_db_cursor.execute(insert_query, (person_url, vehicle_url))\n",
    "\n",
    "# Films_Species Relationship\n",
    "starwars_db_cursor.execute(\"SELECT film_url, species_url FROM films_species\")\n",
    "films_species = starwars_db_cursor.fetchall()\n",
    "for film_url, species_url in films_species:\n",
    "    \n",
    "    insert_query = \"\"\"\n",
    "        INSERT INTO films_species (film_url, species_url)\n",
    "        VALUES (%s, %s)\n",
    "    \"\"\"\n",
    "    normalized_db_cursor.execute(insert_query, (film_url, species_url))\n",
    "\n",
    "# Films_Starships Relationship\n",
    "starwars_db_cursor.execute(\"SELECT film_url, starship_url FROM films_starships\")\n",
    "films_starships = starwars_db_cursor.fetchall()\n",
    "for film_url, starship_url in films_starships:\n",
    "    \n",
    "    insert_query = \"\"\"\n",
    "        INSERT INTO films_starships (film_url, starship_url)\n",
    "        VALUES (%s, %s)\n",
    "    \"\"\"\n",
    "    normalized_db_cursor.execute(insert_query, (film_url, starship_url))\n",
    "\n",
    "# Films_Vehicles Relationship\n",
    "starwars_db_cursor.execute(\"SELECT film_url, vehicle_url FROM films_vehicles\")\n",
    "films_vehicles = starwars_db_cursor.fetchall()\n",
    "for film_url, vehicle_url in films_vehicles:\n",
    "    \n",
    "    insert_query = \"\"\"\n",
    "        INSERT INTO films_vehicles (film_url, vehicle_url)\n",
    "        VALUES (%s, %s)\n",
    "    \"\"\"\n",
    "    normalized_db_cursor.execute(insert_query, (film_url, vehicle_url))\n",
    "\n",
    "# Films_Planets Relationship\n",
    "starwars_db_cursor.execute(\"SELECT film_url, planet_url FROM films_planets\")\n",
    "films_planets = starwars_db_cursor.fetchall()\n",
    "for film_url, planet_url in films_planets:\n",
    "    \n",
    "    insert_query = \"\"\"\n",
    "        INSERT INTO films_planets (film_url, planet_url)\n",
    "        VALUES (%s, %s)\n",
    "    \"\"\"\n",
    "    normalized_db_cursor.execute(insert_query, (film_url, planet_url))\n",
    "\n",
    "# Commit the transaction\n",
    "normalized_db_conn.commit()\n",
    "\n",
    "# ============================================================\n",
    "# End of PHASE 3\n",
    "# ============================================================\n",
    "\n",
    "# ============================================================\n",
    "# PHASE 4: Migrating Ratings and Rating Providers Data from starwars_db to normalized_starwars_db\n",
    "# ============================================================\n",
    "\n",
    "# Step 1: Fetch distinct rating provider names\n",
    "starwars_db_cursor.execute(\"SELECT DISTINCT name FROM rating_providers WHERE name IS NOT NULL\")\n",
    "rating_providers = starwars_db_cursor.fetchall()\n",
    "\n",
    "# Function to convert provider name to a valid column name\n",
    "def sanitize_column_name(name):\n",
    "    return name.strip().lower().replace(' ', '_').replace('-', '_') + '_rating'\n",
    "\n",
    "# Step 2: Add rating columns to the `films` table\n",
    "for provider in rating_providers:\n",
    "    column_name = sanitize_column_name(provider[0])\n",
    "    alter_query = f\"\"\"\n",
    "        ALTER TABLE films\n",
    "        ADD COLUMN IF NOT EXISTS {column_name} NUMERIC\n",
    "    \"\"\"\n",
    "    normalized_db_cursor.execute(alter_query)\n",
    "\n",
    "# Commit to save the schema changes\n",
    "normalized_db_conn.commit()\n",
    "\n",
    "# Step 3: Fetch rating data from source\n",
    "starwars_db_cursor.execute(\"\"\"\n",
    "    SELECT r.film_id, rp.name, r.rating_value\n",
    "    FROM ratings r\n",
    "    JOIN rating_providers rp ON r.rating_provider_id = rp.id\n",
    "\"\"\")\n",
    "\n",
    "ratings = starwars_db_cursor.fetchall()\n",
    "\n",
    "# Step 4: Normalize and insert ratings into `films` table\n",
    "for film_id, provider_name, rating_value in ratings:\n",
    "    column_name = sanitize_column_name(provider_name)\n",
    "\n",
    "    # Normalize the rating value\n",
    "    if isinstance(rating_value, str):\n",
    "        rating_value = rating_value.strip()\n",
    "        if '%' in rating_value:\n",
    "            rating_value = float(rating_value.strip('%'))\n",
    "        elif '/' in rating_value:\n",
    "            numerator, denominator = rating_value.split('/')\n",
    "            rating_value = float(numerator)\n",
    "            denominator = float(denominator)\n",
    "            if denominator == 10:\n",
    "                rating_value *= 10\n",
    "        elif '.' in rating_value:\n",
    "            rating_value = float(rating_value)\n",
    "            if rating_value < 1:\n",
    "                rating_value *= 100\n",
    "            else:\n",
    "                rating_value *= 10\n",
    "        else:\n",
    "            rating_value = float(rating_value)\n",
    "\n",
    "    # Clamp to range 0100\n",
    "    rating_value = min(max(rating_value, 0), 100)\n",
    "\n",
    "    # Update the rating value in the films table\n",
    "    update_query = f\"\"\"\n",
    "        UPDATE films\n",
    "        SET {column_name} = %s\n",
    "        WHERE id = %s\n",
    "    \"\"\"\n",
    "    normalized_db_cursor.execute(update_query, (rating_value, film_id))\n",
    "\n",
    "# Final commit\n",
    "normalized_db_conn.commit()\n",
    "\n",
    "# ============================================================\n",
    "# End of PHASE 4\n",
    "# ============================================================\n",
    "\n",
    "# ============================================================\n",
    "# PHASE 5: Migrating Movie Metadata to Normalized Structure\n",
    "# ============================================================\n",
    "\n",
    "# Fetch all movie metadata from the old movie_metadata table\n",
    "starwars_db_cursor.execute(\"\"\"\n",
    "    SELECT id, popularity, keywords, overview, runtime\n",
    "    FROM movie_metadata\n",
    "\"\"\")\n",
    "\n",
    "movie_metadata_rows = starwars_db_cursor.fetchall()\n",
    "\n",
    "# Insert keywords into the normalized `keywords` table and film details into the `films` table\n",
    "for metadata in movie_metadata_rows:\n",
    "    film_id, popularity, keywords, overview, runtime = metadata\n",
    "\n",
    "    # Insert `overview` and `runtime` into the `films` table\n",
    "    normalized_db_cursor.execute(\"\"\"\n",
    "        UPDATE films \n",
    "        SET overview = %s, runtime = %s\n",
    "        WHERE id = %s\n",
    "    \"\"\", (overview, runtime, film_id))\n",
    "\n",
    "    # Split the keywords into a list (assuming they are comma-separated)\n",
    "    keyword_list = keywords.split(',') if keywords else []\n",
    "    \n",
    "    for keyword in keyword_list:\n",
    "        # Strip whitespace and handle duplicates\n",
    "        keyword = keyword.strip()\n",
    "        \n",
    "        if keyword:\n",
    "            # Check if the keyword already exists in the `keywords` table\n",
    "            normalized_db_cursor.execute(\"SELECT id FROM keywords WHERE keyword = %s\", (keyword,))\n",
    "            keyword_row = normalized_db_cursor.fetchone()\n",
    "            \n",
    "            if keyword_row:\n",
    "                keyword_id = keyword_row[0]\n",
    "            else:\n",
    "                # Insert new keyword if it doesn't exist\n",
    "                normalized_db_cursor.execute(\"INSERT INTO keywords (keyword) VALUES (%s) RETURNING id\", (keyword,))\n",
    "                keyword_id = normalized_db_cursor.fetchone()[0]\n",
    "\n",
    "            # Insert into the new movie_metadata table\n",
    "            normalized_db_cursor.execute(\"\"\"\n",
    "                INSERT INTO movie_metadata (film_id, keyword_id)\n",
    "                VALUES (%s, %s)\n",
    "            \"\"\", (film_id, keyword_id))\n",
    "\n",
    "# Commit the changes to the normalized database\n",
    "normalized_db_conn.commit()\n",
    "\n",
    "# ============================================================\n",
    "# End of PHASE 5\n",
    "# ============================================================\n",
    "\n",
    "\n",
    "# Close the cursors and connections\n",
    "starwars_db_cursor.close()\n",
    "normalized_db_cursor.close()\n",
    "starwars_db_conn.close()\n",
    "normalized_db_conn.close()\n",
    "\n",
    "print(\"Films table populated successfully in normalized_starwars_db!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Files and Scripts\n",
    "\n",
    "Once the normalized database has been structured and populated with data, we now proceed to export the data into CSVs to be imported into our Neo4j database.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import psycopg2\n",
    "import csv\n",
    "\n",
    "# Load environment variables from the .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Connect to PostgreSQL\n",
    "conn = psycopg2.connect(\n",
    "    dbname=os.getenv(\"NORMALIZED_DB_NAME\"),\n",
    "    user= os.getenv(\"DB_USER\"),\n",
    "    password=os.getenv(\"DB_PASSWORD\"),\n",
    "    host=os.getenv(\"DB_HOST\"),\n",
    "    port=os.getenv(\"DB_PORT\")\n",
    ")\n",
    "\n",
    "# Create a cursor to interact with the database\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Define a function to fetch data and write it to CSV\n",
    "def export_to_csv(query, filename):\n",
    "    cursor.execute(query)\n",
    "    rows = cursor.fetchall()\n",
    "    with open(filename, 'w', newline='', encoding='utf-8') as f:\n",
    "        writer = csv.writer(f)\n",
    "        # Write headers based on the query column names\n",
    "        writer.writerow([desc[0] for desc in cursor.description])\n",
    "        writer.writerows(rows)\n",
    "    print(f\"Data exported to {filename}\")\n",
    "\n",
    "# ===========================\n",
    "# Export Films Table\n",
    "# ===========================\n",
    "films_query = \"\"\"\n",
    "SELECT *\n",
    "FROM films;\n",
    "\"\"\"\n",
    "export_to_csv(films_query, 'migration-csv-tables/films.csv')\n",
    "\n",
    "# ===========================\n",
    "# Export People Table\n",
    "# ===========================\n",
    "people_query = \"\"\"\n",
    "SELECT *\n",
    "FROM people;\n",
    "\"\"\"\n",
    "export_to_csv(people_query, 'migration-csv-tables/people.csv')\n",
    "\n",
    "# ===========================\n",
    "# Export Starships Table\n",
    "# ===========================\n",
    "starships_query = \"\"\"\n",
    "SELECT *\n",
    "FROM starships;\n",
    "\"\"\"\n",
    "export_to_csv(starships_query, 'migration-csv-tables/starships.csv')\n",
    "\n",
    "# ===========================\n",
    "# Export Vehicles Table\n",
    "# ===========================\n",
    "vehicles_query = \"\"\"\n",
    "SELECT *\n",
    "FROM vehicles;\n",
    "\"\"\"\n",
    "export_to_csv(vehicles_query, 'migration-csv-tables/vehicles.csv')\n",
    "\n",
    "# ===========================\n",
    "# Export Species Table\n",
    "# ===========================\n",
    "species_query = \"\"\"\n",
    "SELECT *\n",
    "FROM species;\n",
    "\"\"\"\n",
    "export_to_csv(species_query, 'migration-csv-tables/species.csv')\n",
    "\n",
    "# ===========================\n",
    "# Export Planets Table\n",
    "# ===========================\n",
    "planets_query = \"\"\"\n",
    "SELECT *\n",
    "FROM planets;\n",
    "\"\"\"\n",
    "export_to_csv(planets_query, 'migration-csv-tables/planets.csv')\n",
    "\n",
    "# ===========================\n",
    "# Export Keywords Table\n",
    "# ===========================\n",
    "keywords_query = \"\"\"\n",
    "SELECT id, keyword FROM keywords;\n",
    "\"\"\"\n",
    "export_to_csv(keywords_query, 'migration-csv-tables/keywords.csv')\n",
    "\n",
    "# ===========================\n",
    "# Export Movie Metadata Table\n",
    "# ===========================\n",
    "movie_metadata_query = \"\"\"\n",
    "SELECT film_id, keyword_id FROM movie_metadata;\n",
    "\"\"\"\n",
    "export_to_csv(movie_metadata_query, 'migration-csv-tables/movie_metadata.csv')\n",
    "\n",
    "# ===========================\n",
    "# Export Rating Providers Table\n",
    "# ===========================\n",
    "rating_providers_query = \"\"\"\n",
    "SELECT id, name FROM rating_providers;\n",
    "\"\"\"\n",
    "export_to_csv(rating_providers_query, 'migration-csv-tables/rating_providers.csv')\n",
    "\n",
    "# ===========================\n",
    "# Export Ratings Table\n",
    "# ===========================\n",
    "ratings_query = \"\"\"\n",
    "SELECT film_id, rating_provider_id, rating_value FROM ratings;\n",
    "\"\"\"\n",
    "export_to_csv(ratings_query, 'migration-csv-tables/ratings.csv')\n",
    "\n",
    "def export_aggregated_relation(query, filename):\n",
    "    cursor.execute(query)\n",
    "    rows = cursor.fetchall()\n",
    "    with open(filename, 'w', newline='', encoding='utf-8') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow([desc[0] for desc in cursor.description])\n",
    "        writer.writerows(rows)\n",
    "    print(f\"Exported: {filename}\")\n",
    "\n",
    "# -----------------------\n",
    "# People  Films\n",
    "# -----------------------\n",
    "export_aggregated_relation(\"\"\"\n",
    "    SELECT person_url, string_agg(film_url, ',') AS films\n",
    "    FROM people_films\n",
    "    GROUP BY person_url\n",
    "\"\"\", \"migration-csv-tables/people_films_array.csv\")\n",
    "\n",
    "# -----------------------\n",
    "# People  Species\n",
    "# -----------------------\n",
    "export_aggregated_relation(\"\"\"\n",
    "    SELECT person_url, string_agg(species_url, ',') AS species\n",
    "    FROM people_species\n",
    "    GROUP BY person_url\n",
    "\"\"\", \"migration-csv-tables/people_species_array.csv\")\n",
    "\n",
    "# -----------------------\n",
    "# People  Starships\n",
    "# -----------------------\n",
    "export_aggregated_relation(\"\"\"\n",
    "    SELECT person_url, string_agg(starship_url, ',') AS starships\n",
    "    FROM people_starships\n",
    "    GROUP BY person_url\n",
    "\"\"\", \"migration-csv-tables/people_starships_array.csv\")\n",
    "\n",
    "# -----------------------\n",
    "# People  Vehicles\n",
    "# -----------------------\n",
    "export_aggregated_relation(\"\"\"\n",
    "    SELECT person_url, string_agg(vehicle_url, ',') AS vehicles\n",
    "    FROM people_vehicles\n",
    "    GROUP BY person_url\n",
    "\"\"\", \"migration-csv-tables/people_vehicles_array.csv\")\n",
    "\n",
    "# -----------------------\n",
    "# Films  Species\n",
    "# -----------------------\n",
    "export_aggregated_relation(\"\"\"\n",
    "    SELECT film_url, string_agg(species_url, ',') AS species\n",
    "    FROM films_species\n",
    "    GROUP BY film_url\n",
    "\"\"\", \"migration-csv-tables/films_species_array.csv\")\n",
    "\n",
    "# -----------------------\n",
    "# Films  Starships\n",
    "# -----------------------\n",
    "export_aggregated_relation(\"\"\"\n",
    "    SELECT film_url, string_agg(starship_url, ',') AS starships\n",
    "    FROM films_starships\n",
    "    GROUP BY film_url\n",
    "\"\"\", \"migration-csv-tables/films_starships_array.csv\")\n",
    "\n",
    "# -----------------------\n",
    "# Films  Vehicles\n",
    "# -----------------------\n",
    "export_aggregated_relation(\"\"\"\n",
    "    SELECT film_url, string_agg(vehicle_url, ',') AS vehicles\n",
    "    FROM films_vehicles\n",
    "    GROUP BY film_url\n",
    "\"\"\", \"migration-csv-tables/films_vehicles_array.csv\")\n",
    "\n",
    "# -----------------------\n",
    "# Films  Planets\n",
    "# -----------------------\n",
    "export_aggregated_relation(\"\"\"\n",
    "    SELECT film_url, string_agg(planet_url, ',') AS planets\n",
    "    FROM films_planets\n",
    "    GROUP BY film_url\n",
    "\"\"\", \"migration-csv-tables/films_planets_array.csv\")\n",
    "\n",
    "# -----------------------\n",
    "# Films  Keywords\n",
    "# -----------------------\n",
    "export_aggregated_relation(\"\"\"\n",
    "    SELECT f.url AS film_url, string_agg(k.keyword, ',') AS keywords\n",
    "    FROM movie_metadata mm\n",
    "    JOIN films f ON mm.film_id = f.id\n",
    "    JOIN keywords k ON mm.keyword_id = k.id\n",
    "    GROUP BY f.url\n",
    "\"\"\", \"migration-csv-tables/films_keywords_array.csv\")\n",
    "\n",
    "# Close the cursor and connection\n",
    "cursor.close()\n",
    "conn.close()\n",
    "\n",
    "print(\"All data exported successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then proceed to write a script that enables us to make use of the exported CSV files and import into our Neo4j database.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neo4j import GraphDatabase\n",
    "import os\n",
    "import csv\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from the .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Path to CSVs\n",
    "CSV_DIR = \"migration-csv-tables\"\n",
    "\n",
    "driver = GraphDatabase.driver(\n",
    "    os.getenv(\"NEO4J_URI\"),\n",
    "    auth=(os.getenv(\"NEO4J_USER\"), os.getenv(\"NEO4J_PASSWORD\"))\n",
    ")\n",
    "\n",
    "# Phase 1: Create nodes from CSVs with dynamic fields\n",
    "def create_nodes(tx, label, csv_file):\n",
    "    with open(os.path.join(CSV_DIR, csv_file), newline='', encoding='utf-8') as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        headers = reader.fieldnames\n",
    "        for row in reader:\n",
    "            props = {k: row[k] for k in headers}\n",
    "            prop_str = \", \".join(f\"{k}: ${k}\" for k in headers)\n",
    "            query = f\"MERGE (n:{label} {{ {prop_str} }})\"\n",
    "            tx.run(query, **props)\n",
    "\n",
    "# Phase 2: Add arrays as node attributes using dynamic detection\n",
    "def add_array_property(tx, label, csv_file):\n",
    "    with open(os.path.join(CSV_DIR, csv_file), newline='', encoding='utf-8') as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        headers = reader.fieldnames\n",
    "        if len(headers) != 2:\n",
    "            raise ValueError(f\"Expected exactly 2 columns in {csv_file}, got {headers}\")\n",
    "        id_field, array_field = headers\n",
    "\n",
    "        for row in reader:\n",
    "            identifier = row[id_field]\n",
    "            array_data = row[array_field].split(\",\") if row[array_field] else []\n",
    "            query = f\"\"\"\n",
    "                MATCH (n:{label} {{url: $id}})\n",
    "                SET n.{array_field} = $items\n",
    "            \"\"\"\n",
    "            tx.run(query, id=identifier, items=array_data)\n",
    "\n",
    "with driver.session() as session:\n",
    "\n",
    "    # ========= Phase 1: Import Nodes =========\n",
    "    print(\" Importing node data...\")\n",
    "\n",
    "    session.execute_write(create_nodes, \"Film\", \"films.csv\")\n",
    "    session.execute_write(create_nodes, \"Person\", \"people.csv\")\n",
    "    session.execute_write(create_nodes, \"Starship\", \"starships.csv\")\n",
    "    session.execute_write(create_nodes, \"Vehicle\", \"vehicles.csv\")\n",
    "    session.execute_write(create_nodes, \"Species\", \"species.csv\")\n",
    "    session.execute_write(create_nodes, \"Planet\", \"planets.csv\")\n",
    "\n",
    "    print(\" Nodes imported!\")\n",
    "\n",
    "    # ========= Phase 2: Add arrays =========\n",
    "    print(\" Adding array attributes...\")\n",
    "\n",
    "    session.execute_write(add_array_property, \"Person\", \"people_films_array.csv\")\n",
    "    session.execute_write(add_array_property, \"Person\", \"people_species_array.csv\")\n",
    "    session.execute_write(add_array_property, \"Person\", \"people_starships_array.csv\")\n",
    "    session.execute_write(add_array_property, \"Person\", \"people_vehicles_array.csv\")\n",
    "\n",
    "    session.execute_write(add_array_property, \"Film\", \"films_species_array.csv\")\n",
    "    session.execute_write(add_array_property, \"Film\", \"films_starships_array.csv\")\n",
    "    session.execute_write(add_array_property, \"Film\", \"films_vehicles_array.csv\")\n",
    "    session.execute_write(add_array_property, \"Film\", \"films_planets_array.csv\")\n",
    "    session.execute_write(add_array_property, \"Film\", \"films_keywords_array.csv\")\n",
    "\n",
    "    print(\" Array attributes added!\")\n",
    "\n",
    "driver.close()\n",
    "print(\" Neo4j import complete.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Queries\n",
    "\n",
    "## A) Find the total number of films, total number of planets, total number of species in the database.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from neo4j import GraphDatabase\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Neo4j driver setup\n",
    "driver = GraphDatabase.driver(\n",
    "    os.getenv(\"NEO4J_URI\"),\n",
    "    auth=(os.getenv(\"NEO4J_USER\"), os.getenv(\"NEO4J_PASSWORD\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "// Total number of films\n",
    "MATCH (f:Film)\n",
    "RETURN count(f) AS total_films;\n",
    "\n",
    "// Total number of planets\n",
    "MATCH (p:Planet)\n",
    "RETURN count(p) AS total_planets;\n",
    "\n",
    "// Total number of species\n",
    "MATCH (s:Species)\n",
    "RETURN count(s) AS total_species;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Record total_films=6>\n",
      "<Record total_planets=60>\n",
      "<Record total_species=37>\n"
     ]
    }
   ],
   "source": [
    "QUERY_FILE = \"queries/01_total_counts.cypher\"\n",
    "\n",
    "# Load and split the queries (assumes each query ends with a semicolon)\n",
    "with open(QUERY_FILE, 'r', encoding='utf-8') as file:\n",
    "    contents = file.read()\n",
    "    queries = [q.strip() for q in contents.split(';') if q.strip()]\n",
    "\n",
    "with driver.session() as session:\n",
    "    for i, query in enumerate(queries):\n",
    "        result = session.run(query)\n",
    "        for record in result:\n",
    "            print(record)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B) Find all planets associated with a sample film.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "MATCH (f:Film {title: \"A New Hope\"})\n",
    "WITH f, f.planets AS planet_urls\n",
    "UNWIND planet_urls AS planet_url\n",
    "MATCH (p:Planet {url: planet_url})\n",
    "RETURN p.name AS planet_name;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Record planet_name='Tatooine'>\n",
      "<Record planet_name='Alderaan'>\n",
      "<Record planet_name='Yavin IV'>\n"
     ]
    }
   ],
   "source": [
    "QUERY_FILE = \"queries/02_planets_for_sample_film.cypher\"\n",
    "\n",
    "with open(QUERY_FILE, 'r', encoding='utf-8') as file:\n",
    "    cypher = file.read()\n",
    "\n",
    "with driver.session() as session:\n",
    "    result = session.run(cypher)\n",
    "    for record in result:\n",
    "        print(record)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C) Find all films that are released after the year 1980 and has an imdb-rating of at least 5.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "MATCH (f:Film)\n",
    "WHERE f.release_date > \"1980-01-01\" \n",
    "  AND toInteger(f.internet_movie_database_rating) >= 50\n",
    "RETURN f.title, f.release_date, f.internet_movie_database_rating;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Record f.title='The Empire Strikes Back' f.release_date='1980-05-17' f.internet_movie_database_rating='87.0'>\n",
      "<Record f.title='Return of the Jedi' f.release_date='1983-05-25' f.internet_movie_database_rating='83.0'>\n",
      "<Record f.title='The Phantom Menace' f.release_date='1999-05-19' f.internet_movie_database_rating='65.0'>\n",
      "<Record f.title='Attack of the Clones' f.release_date='2002-05-16' f.internet_movie_database_rating='66.0'>\n",
      "<Record f.title='Revenge of the Sith' f.release_date='2005-05-19' f.internet_movie_database_rating='76.0'>\n"
     ]
    }
   ],
   "source": [
    "QUERY_FILE = \"queries/03_films_after_1980_with_rating_5.cypher\"\n",
    "\n",
    "with open(QUERY_FILE, 'r', encoding='utf-8') as file:\n",
    "    cypher = file.read()\n",
    "\n",
    "with driver.session() as session:\n",
    "    result = session.run(cypher)\n",
    "    for record in result:\n",
    "        print(record)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## D) Find all films with two vehicles of your choice. List films that may be associated with either of the vehicles (not necessarily both).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "MATCH (f:Film)\n",
    "MATCH (v:Vehicle)\n",
    "WHERE v.name IN ['Sith speeder', 'Koro-2 Exodrive airspeeder'] \n",
    "AND v.url IN f.vehicles\n",
    "RETURN f.title, f.release_date, COLLECT(v.name) AS vehicles;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Record f.title='The Phantom Menace' f.release_date='1999-05-19' vehicles=['Sith speeder']>\n",
      "<Record f.title='Attack of the Clones' f.release_date='2002-05-16' vehicles=['Koro-2 Exodrive airspeeder']>\n"
     ]
    }
   ],
   "source": [
    "QUERY_FILE = \"queries/04_films_with_vehicles.cypher\"\n",
    "\n",
    "with open(QUERY_FILE, 'r', encoding='utf-8') as file:\n",
    "    cypher = file.read()\n",
    "\n",
    "with driver.session() as session:\n",
    "    result = session.run(cypher)\n",
    "    for record in result:\n",
    "        print(record)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## E) Find the film with largest number of keywords.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "MATCH (f:Film)\n",
    "WITH f, size(f.keywords) AS num_keywords\n",
    "ORDER BY num_keywords DESC\n",
    "LIMIT 1\n",
    "RETURN f.title, num_keywords;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Record f.title='A New Hope' num_keywords=17>\n"
     ]
    }
   ],
   "source": [
    "QUERY_FILE = \"queries/05_film_with_largest_keywords.cypher\"\n",
    "\n",
    "with open(QUERY_FILE, 'r', encoding='utf-8') as file:\n",
    "    cypher = file.read()\n",
    "\n",
    "with driver.session() as session:\n",
    "    result = session.run(cypher)\n",
    "    for record in result:\n",
    "        print(record)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## F) Build full text search index to query movie overview.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "CREATE FULLTEXT INDEX filmOverviewIndex FOR (n:Film) ON EACH [n.overview];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Fulltext index dropped if it existed, and created.\n"
     ]
    }
   ],
   "source": [
    "QUERY_FILE = \"queries/06_create_fulltext_index.cypher\"\n",
    "\n",
    "with open(QUERY_FILE, 'r', encoding='utf-8') as file:\n",
    "    queries = [q.strip() for q in file.read().split(';') if q.strip()]\n",
    "\n",
    "with driver.session() as session:\n",
    "    for query in queries:\n",
    "        session.run(query)\n",
    "\n",
    "print(\" Fulltext index dropped if it existed, and created.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## G) Write a full text search query and search for some sample text of your choice.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "CALL db.index.fulltext.queryNodes(\"filmOverviewIndex\", \"galaxy\")\n",
    "YIELD node, score\n",
    "RETURN node.title AS title, node.overview AS overview, score\n",
    "ORDER BY score DESC\n",
    "LIMIT 10;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Record title='Attack of the Clones' overview='Following an assassination attempt on Senator Padm Amidala, Jedi Knights Anakin Skywalker and Obi-Wan Kenobi investigate a mysterious plot that could change the galaxy forever.' score=0.7931073307991028>\n"
     ]
    }
   ],
   "source": [
    "QUERY_FILE = \"queries/07_fulltext_search_query.cypher\"\n",
    "\n",
    "with open(QUERY_FILE, 'r', encoding='utf-8') as file:\n",
    "    cypher = file.read()\n",
    "\n",
    "with driver.session() as session:\n",
    "    result = session.run(cypher)\n",
    "    for record in result:\n",
    "        print(record)\n",
    "\n",
    "driver.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
